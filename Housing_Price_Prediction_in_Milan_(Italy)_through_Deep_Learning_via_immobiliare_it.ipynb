{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Housing Price Prediction in Milan (Italy) through Deep Learning via immobiliare.it.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kp788-zijJ5_",
        "Hldwisi3Pj2k",
        "aL71vrUhJt3Q",
        "pkpwkeWLvOFd",
        "z38bhe1xKDwO",
        "oqEId5Nja8Wf",
        "7sFiJjLRbC5_"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKt8RZf6Pew0L0y1frIG0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8e93c76e1a547888033dfc09c57141c": {
          "model_module": "jupyter-gmaps",
          "model_name": "FigureModel",
          "state": {
            "_view_name": "FigureView",
            "_view_module": "jupyter-gmaps",
            "_dom_classes": [],
            "_model_name": "FigureModel",
            "_map": "IPY_MODEL_a349db61f5354707a50163ce8be968d4",
            "_model_module_version": "0.9.0",
            "_view_count": null,
            "_view_module_version": "0.9.0",
            "_toolbar": "IPY_MODEL_a1be4bf50d0d4cdfb1f17895e9ead7ba",
            "_errors_box": "IPY_MODEL_3ee96088a6d14b3fb5278fca096c37b8",
            "_model_module": "jupyter-gmaps",
            "layout": "IPY_MODEL_0b1ca327cd9145348756ebbed4e99197"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreabazerla/real-estate/blob/main/Housing_Price_Prediction_in_Milan_(Italy)_through_Deep_Learning_via_immobiliare_it.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxX68uAbjv4j"
      },
      "source": [
        "# Housing Price Prediction in Milan (Italy) through Deep Learning via immobiliare.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ehFWpWmwkL"
      },
      "source": [
        "<img src=\"https://media.giphy.com/media/gTURHJs4e2Ies/source.gif\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub9J4KGqPTlV"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import math\n",
        "import locale\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "from google.colab import files\n",
        "import requests\n",
        "from enum import Enum \n",
        "from random import uniform\n",
        "import time\n",
        "import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import functools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2E31Y_ltpbT"
      },
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mitDG-fzISZ9"
      },
      "source": [
        "def get_timestamp():\n",
        "  return str(int(time.time()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp788-zijJ5_"
      },
      "source": [
        "## Web Scraping: immobiliare.it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4IVwi70dIw"
      },
      "source": [
        "PRODUCTION = True\n",
        "GET_ADS_LINKS = False\n",
        "GET_ADS_LIST = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTs8ZzrGrMV7"
      },
      "source": [
        "class Contract(Enum):\n",
        "  VENDITA = 'vendita'\n",
        "  AFFITTO = 'affitto'\n",
        " \n",
        "class Area(Enum):\n",
        "  MILANO = 'milano'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHhqN9p1pp89"
      },
      "source": [
        "slash = '/'\n",
        "https = 'https://'\n",
        "website = 'www.immobiliare.it'\n",
        "contract = Contract.VENDITA.value + '-case'\n",
        "area = Area.MILANO.value\n",
        "sort = '?criterio=rilevanza'\n",
        " \n",
        "url = https + website + slash + contract + slash + area + slash + sort\n",
        " \n",
        "print('url = ' + url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sDTxZLWoypo"
      },
      "source": [
        "sleep_min = 2\n",
        "sleep_max = 3\n",
        "\n",
        "def sleep_default():\n",
        "  time.sleep(uniform(sleep_min, sleep_max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hldwisi3Pj2k"
      },
      "source": [
        "### Ads Link Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujp1eEaWqpda"
      },
      "source": [
        "def get_last_page(url):\n",
        "  sleep_default()\n",
        "  \n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  \n",
        "    ul_pagination = soup.find(\"ul\", class_ = \"pagination pagination__number\")\n",
        "    li_list = ul_pagination.find_all(\"li\")\n",
        "    last_page = int(li_list[-1].get_text().strip())\n",
        "  \n",
        "    return last_page\n",
        "  \n",
        "  except requests.exceptions.RequestException as e:\n",
        "    raise SystemExit(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAvqYAvLTwe"
      },
      "source": [
        "def get_ads_link_list(url, first_page, last_page):\n",
        "  ads_link_list = []\n",
        "  \n",
        "  pag = first_page\n",
        "  \n",
        "  while (pag <= last_page):\n",
        "    if (pag > 1):\n",
        "      url = url + '&pag=' + str(pag)\n",
        "    \n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "\n",
        "      soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    \n",
        "      ads_list = soup.find('ul', class_ = 'annunci-list')\n",
        "      ad_item_list = ads_list.find_all('div', class_ = 'listing-item_body--content')\n",
        "      for ad_item in ad_item_list:\n",
        "        a_list = ad_item.find_all(\"a\")\n",
        "        for a in a_list:\n",
        "          href = a[\"href\"]\n",
        "          ads_link_list.append(href)\n",
        "    \n",
        "    except Exception as e:\n",
        "      logging.exception(e)\n",
        "      print(str(pag))\n",
        "      pass\n",
        "    \n",
        "    pag += 1\n",
        " \n",
        "    sleep_default()\n",
        "  \n",
        "  return ads_link_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds-RxO8FRWJp"
      },
      "source": [
        "if PRODUCTION:\n",
        "  if GET_ADS_LINKS:\n",
        "    first_page = 1\n",
        "    #last_page = 631\n",
        "    last_page = get_last_page(url)\n",
        "  \n",
        "    ads_link_list = get_ads_link_list(url, first_page, last_page)\n",
        "    ads_link_list = list(dict.fromkeys(ads_link_list))\n",
        "    \n",
        "    print('Total number of ads = ' + str(len(ads_link_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRYgjfjwTaZD"
      },
      "source": [
        "df_links = pd.DataFrame({'Links' : list(ads_link_list)})\n",
        "\n",
        "csv_links = 'Links_' + str(int(time.time())) + '_' + str(first_page) + '_' + str(last_page) + '.csv'\n",
        "df_links.to_csv(csv_links, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-miVRuHolW"
      },
      "source": [
        "display(df_links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoV65WKTvsgT"
      },
      "source": [
        "files.download(csv_links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66tYwTTjP4ly"
      },
      "source": [
        "### Ads Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykpkKlkZogG3"
      },
      "source": [
        "def get_ad_title(soup):\n",
        "  titleBlock__title = soup.find('span', class_ = 'im-titleBlock__title')\n",
        "  if titleBlock__title is not None:\n",
        "    return titleBlock__title.get_text()\n",
        "  else:\n",
        "    return ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb-N84mK6Ipm"
      },
      "source": [
        "def get_ad_price(soup):\n",
        "  mainFeatures__price = soup.find_all('li', class_ = 'im-mainFeatures__price')\n",
        "  if mainFeatures__price:\n",
        "    return mainFeatures__price[0].get_text().replace('\\n', '').strip()\n",
        "  else:\n",
        "    return ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwAGku2_5V1"
      },
      "source": [
        "def get_ad_main_feature(soup):\n",
        "  main_features = {}\n",
        "  \n",
        "  mainFeatures = soup.find('div', class_ = 'im-mainFeatures')\n",
        "  \n",
        "  li_list = mainFeatures.find_all('li')\n",
        "  for li in li_list[1:]:\n",
        "    value = li.find('span', class_=\"im-mainFeatures__value\").get_text().replace('\\n', '').strip()\n",
        "    label = li.find('span', class_=\"im-mainFeatures__label\").get_text().replace('\\n', '').strip()\n",
        "    \n",
        "    if (label == 'bagno' or label == 'bagni'):\n",
        "      label = 'bagni'\n",
        "    \n",
        "    if (label == 'locale' or label == 'locali'):\n",
        "      label = 'locali'\n",
        "    \n",
        "    main_features[label] = value\n",
        "  \n",
        "  return main_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgHNdLhX23BI"
      },
      "source": [
        "def get_ad_description(soup):\n",
        "  description__text = soup.find('div', class_ = 'im-description__text')\n",
        "  if description__text is not None:\n",
        "    return description__text.get_text()\n",
        "  else:\n",
        "    return ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0-tj0Geel2"
      },
      "source": [
        "def get_ad_locations(soup):\n",
        "  location_list = []\n",
        "  \n",
        "  titleBlock__link = soup.find('a', class_ = 'im-titleBlock__link')\n",
        "  if titleBlock__link is None:\n",
        "    titleBlock__link = soup.find('h1', class_ = 'im-titleBlock__content')\n",
        "\n",
        "  location = titleBlock__link.find_all('span', class_ = 'im-location')\n",
        "  \n",
        "  try:\n",
        "    area = location[0].get_text().strip()\n",
        "  except IndexError:\n",
        "    area = ''\n",
        "  \n",
        "  try:\n",
        "    district = location[1].get_text().strip()\n",
        "  except IndexError:\n",
        "    district = ''\n",
        "\n",
        "  try:\n",
        "    address = location[2].get_text().strip()\n",
        "  except IndexError:\n",
        "    address = ''\n",
        "\n",
        "  return [area, district, address]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhuVyk5h_Kfb"
      },
      "source": [
        "def get_ad_feature_list(soup):\n",
        "  features = {}\n",
        "  \n",
        "  features__list = soup.find_all(\"dl\", class_ = \"im-features__list\")\n",
        "  \n",
        "  for feature_block in features__list:\n",
        "    feature__title_list = feature_block.find_all('dt', class_ = 'im-features__title')\n",
        "  \n",
        "    for feature__title in feature__title_list:\n",
        "      feature__value = feature__title.findNext('dd')\n",
        "  \n",
        "      if ('im-features__tagContainer' in feature__value.get('class')):\n",
        "        features__tag_array = []\n",
        "\n",
        "        features__tag_list = soup.find_all('span', class_ = 'im-features__tag')\n",
        "        for feature__tag in features__tag_list:\n",
        "          features__tag_array.append(feature__tag.get_text().strip())\n",
        "  \n",
        "        features__tag_list_string = ','.join(features__tag_array)\n",
        "        feature__value_2 = features__tag_list_string\n",
        "  \n",
        "      else:\n",
        "        feature__value_2 = feature__value.get_text().strip()\n",
        "  \n",
        "      feature__title_2 = feature__title.get_text().strip()\n",
        "      features['f_' + feature__title_2] = feature__value_2\n",
        "  \n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLEg4LNxGf9L"
      },
      "source": [
        "def get_ad(url):\n",
        "  if 'p-' in url:\n",
        "    return get_ad_multi(url)\n",
        "  else:\n",
        "    return get_ad_single(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILWk45lM2V27"
      },
      "source": [
        "def get_ad_single(url):\n",
        "  ads_list = []\n",
        "  ad_data = {}\n",
        "\n",
        "  ad_data['url'] = url\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    if response:\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "      title = get_ad_title(soup);\n",
        "      ad_data['titolo'] = title\n",
        "\n",
        "      price = get_ad_price(soup);\n",
        "      ad_data['prezzo'] = price\n",
        "\n",
        "      main_features = get_ad_main_feature(soup)\n",
        "      if main_features:\n",
        "        ad_data.update(main_features)\n",
        "\n",
        "      description = get_ad_description(soup);\n",
        "      ad_data['descrizione'] = description\n",
        "\n",
        "      area, district, address = get_ad_locations(soup)\n",
        "      ad_data['area'] = area\n",
        "      ad_data['quartiere'] = district\n",
        "      ad_data['indirizzo'] = address\n",
        "\n",
        "      feature_list = get_ad_feature_list(soup)\n",
        "      if feature_list:\n",
        "        ad_data.update(feature_list)\n",
        "\n",
        "      ad_data['hashcode'] = hash(frozenset(ad_data.items()))\n",
        "\n",
        "      ads_list.append(ad_data)\n",
        "  \n",
        "  except Exception as e:\n",
        "    logging.exception(e)\n",
        "    print(url)\n",
        "    pass\n",
        "\n",
        "  return ads_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOCb5naQ2IML"
      },
      "source": [
        "def get_ad_multi(url):\n",
        "  ads_list = []\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    if response:\n",
        "      soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "      title = get_ad_title(soup);\n",
        "\n",
        "      area, district, address = get_ad_locations(soup)\n",
        "\n",
        "      main_features = get_ad_main_feature(soup)\n",
        "\n",
        "      description = get_ad_description(soup)\n",
        "\n",
        "      feature_list = get_ad_feature_list(soup)\n",
        "\n",
        "      properties__list = soup.find('ul', class_ = 'im-properties__list')\n",
        "      properties__item_list = properties__list.find_all('li', class_ = 'im-properties__item')\n",
        "      for properties__item in properties__item_list:\n",
        "        ad_data = {}\n",
        "\n",
        "        ad_data['url'] = url\n",
        "\n",
        "        ad_data['titolo'] = title\n",
        "\n",
        "        ad_data['area'] = area\n",
        "        ad_data['quartiere'] = district\n",
        "        ad_data['indirizzo'] = address\n",
        "        \n",
        "        price = get_ad_price(properties__item)\n",
        "        ad_data['prezzo'] = price\n",
        "\n",
        "        ad_data['descrizione'] = description\n",
        "\n",
        "        sub_features = get_ad_main_feature(properties__item)\n",
        "        if sub_features:\n",
        "          ad_data.update(sub_features)\n",
        "\n",
        "        title_2 = properties__item.find('p', class_ = 'nd-mediaObject__title')\n",
        "        if title_2 is not None:\n",
        "          ad_data['titolo_2'] = title_2.get_text().strip()\n",
        "\n",
        "        description_2 = properties__item.find('div', class_ = 'im-properties__content')\n",
        "        if description_2 is not None:\n",
        "          ad_data['descrizione_2'] = description_2.get_text()\n",
        "\n",
        "        if feature_list:\n",
        "          ad_data.update(feature_list)\n",
        "\n",
        "        ad_data['hashcode'] = hash(frozenset(ad_data.items()))\n",
        "\n",
        "        ads_list.append(ad_data)\n",
        "\n",
        "  except Exception as e:\n",
        "    logging.exception(e)\n",
        "    print(url)\n",
        "    pass\n",
        "  \n",
        "  return ads_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-evOLRfGpIJ"
      },
      "source": [
        "df_links = pd.read_csv('Links_1616797839_1_630.csv')\n",
        "ads_link_list = df_links['Links'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DnnXijuFbWz"
      },
      "source": [
        "if PRODUCTION:\n",
        "  if GET_ADS_LIST:\n",
        "    df_ads = pd.DataFrame()\n",
        "\n",
        "    first_ad = 1000\n",
        "    last_ad = 1500\n",
        "    #last_ad = len(ads_link_list)\n",
        "\n",
        "    #if (first_ad > last_ad)\n",
        "    \n",
        "    ads_csv = 'Ads_' + get_timestamp() + '_' + str(first_ad) + '_' + str(last_ad - 1) + '.csv'\n",
        "\n",
        "    ads_list = []\n",
        "    for i in tqdm(range(first_ad, last_ad)):\n",
        "\n",
        "      try:\n",
        "        ad_data = get_ad(ads_link_list[i])\n",
        "        for ad in ad_data:\n",
        "          ads_list.append(ad)\n",
        "      except Exception as e:\n",
        "        logging.exception(e)\n",
        "        print(i)\n",
        "        pass\n",
        "      \n",
        "      sleep_default()\n",
        "    \n",
        "    df_ads = pd.DataFrame(ads_list)\n",
        "    df_ads.fillna('', inplace=True)\n",
        "    df_ads.to_csv(ads_csv, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D11eWCH2Qe2w"
      },
      "source": [
        "  display(df_ads)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d2rVUAiJqLs"
      },
      "source": [
        "files.download(ads_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMfGVmeDevm3"
      },
      "source": [
        "ads_folder = 'Ads'\n",
        "file_list = os.listdir(ads_folder)\n",
        "ads_files = [file for file in file_list if file.startswith('Ads')]\n",
        "ads_files.sort()\n",
        "\n",
        "df_files = [None] * len(ads_files)\n",
        "for idx, file in enumerate(ads_files):\n",
        "  df_files[idx] = pd.read_csv(os.path.join(ads_folder, file))\n",
        "\n",
        "df_final = pd.concat(df_files).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "ads_csv_final = 'Ads' + '_' + get_timestamp() + '.csv'\n",
        "df_final.to_csv(ads_csv_final, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a___P2QyGfBt"
      },
      "source": [
        "files.download(ads_csv_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL71vrUhJt3Q"
      },
      "source": [
        "## Clean Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USFywIMmjm7M"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWtia4clIqkX"
      },
      "source": [
        "csv_ads = 'Ads_1617101603.csv'\n",
        "df_ads = pd.read_csv(csv_ads, dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxXW4uzfs_Rw"
      },
      "source": [
        "df_ads.info()\n",
        "df_ads.describe().transpose()\n",
        "display(df_ads.head(10).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w_PoCC_gs9t"
      },
      "source": [
        "df_ads['id'] = range(1, len(df_ads) + 1)\n",
        "df_ads.set_index('id', inplace = True)\n",
        "\n",
        "df_ads = df_ads[~df_ads['url'].str.contains('p-')]\n",
        "\n",
        "index_names = df_ads[\n",
        "  (df_ads['f_offerta minima'].notnull())\n",
        "  | (df_ads['f_rialzo minimo'].notnull())\n",
        "  | (df_ads['f_Spesa prenota debito'].notnull())\n",
        "  | (df_ads['f_Contributo non dovuto'].notnull())\n",
        "  | (df_ads['f_Tribunale'].notnull())\n",
        "  | (df_ads['f_termine presentazione'].notnull())\n",
        "  | (df_ads['f_lotto numero'].notnull())\n",
        "  | (df_ads['f_Deposito cauzionale'].notnull())\n",
        "  | (df_ads['f_luogo vendita'].notnull())\n",
        "  | (df_ads['f_Luogo presentazione'].notnull())\n",
        "  | (df_ads['f_categoria'].notnull())\n",
        "  | (df_ads['f_Procedura'].notnull())\n",
        "  | (df_ads['f_Procedura'].notnull())\n",
        "  | (df_ads['f_numero procedura'].notnull())\n",
        "  | (df_ads['f_Delegato'].notnull())\n",
        "  | (df_ads['f_Giudice'].notnull())\n",
        "  | (df_ads['f_Custode'].notnull())\n",
        "  | (df_ads['f_Dati catastali'].notnull())\n",
        "  | (df_ads['f_Rialzo minimo in caso di gara'].notnull())\n",
        "  | (df_ads['f_Motivo esenzione'].notnull())\n",
        "  | (df_ads['f_note'].notnull())\n",
        "  | (df_ads['f_Rito'].notnull())\n",
        "  | (df_ads['f_Curatore'].notnull())\n",
        "  | (df_ads['f_Altri dati catastali'].notnull())\n",
        "  | (df_ads['f_Deposito conto spese'].notnull())\n",
        "  | (df_ads['f_Cauzione e spese'].notnull())\n",
        "  | (df_ads['f_Referente'].notnull())\n",
        "  | (df_ads['f_valore perizia'].notnull())\n",
        "  | (df_ads['f_Delegato alla vendita'].notnull())\n",
        "].index\n",
        "\n",
        "df_ads = df_ads.drop(index_names)\n",
        "\n",
        "columns_useless = [\n",
        "  'url',\n",
        "  'area',\n",
        "  'descrizione',\n",
        "  'titolo_2',\n",
        "  'descrizione_2',\n",
        "  'f_superficie',\n",
        "  'f_prezzo',\n",
        "  'f_riferimento e Data annuncio',\n",
        "  'f_immobile garantito',\n",
        "  'f_contratto',\n",
        "  'f_unità',\n",
        "  'f_Data di inizio lavori e di consegna prevista',\n",
        "  'f_Indice prest. energetica rinnovabile',\n",
        "  'f_Prestazione energetica del fabbricato',\n",
        "  'f_disponibilità',\n",
        "  'f_certificazione energetica',\n",
        "  'f_numero immobili',\n",
        "  'f_aggiornato il',\n",
        "  'hashcode',\n",
        "  'data vendita',\n",
        "  'f_Tipo vendita',\n",
        "  'f_data vendita',\n",
        "  'f_offerta minima',\n",
        "  'f_rialzo minimo',\n",
        "  'f_Spesa prenota debito',\n",
        "  'f_Contributo non dovuto',\n",
        "  'f_Tribunale',\n",
        "  'f_termine presentazione',\n",
        "  'f_lotto numero',\n",
        "  'f_Deposito cauzionale',\n",
        "  'f_luogo vendita',\n",
        "  'f_Luogo presentazione',\n",
        "  'f_categoria',\n",
        "  'f_Procedura',\n",
        "  'f_numero procedura',\n",
        "  'f_Delegato',\n",
        "  'f_Giudice',\n",
        "  'f_Custode',\n",
        "  'f_Dati catastali',\n",
        "  'f_Rialzo minimo in caso di gara',\n",
        "  'f_Motivo esenzione',\n",
        "  'f_note',\n",
        "  'f_Rito',\n",
        "  'f_Curatore',\n",
        "  'f_Altri dati catastali',\n",
        "  'f_Deposito conto spese',\n",
        "  'f_Cauzione e spese',\n",
        "  'f_Referente',\n",
        "  'f_valore perizia',\n",
        "  'f_Delegato alla vendita'\n",
        "]\n",
        "\n",
        "df_ads = df_ads.drop(columns_useless, axis=1)\n",
        "\n",
        "columns_unique_treshold = df_ads[['quartiere']]\n",
        "df_ads = df_ads[columns_unique_treshold.replace(columns_unique_treshold.apply(pd.Series.value_counts)).gt(10).all(1)]\n",
        "\n",
        "columns_unique_treshold_2 = df_ads[['f_stato']]\n",
        "df_ads = df_ads[columns_unique_treshold_2.replace(columns_unique_treshold_2.apply(pd.Series.value_counts)).gt(10).all(1)]\n",
        "\n",
        "columns_unique_treshold_3 = df_ads[['f_Tipo proprietà']]\n",
        "df_ads = df_ads[columns_unique_treshold_3.replace(columns_unique_treshold_3.apply(pd.Series.value_counts)).gt(10).all(1)]\n",
        "\n",
        "columns_unique_treshold_4 = df_ads[['f_tipologia']]\n",
        "df_ads = df_ads[columns_unique_treshold_4.replace(columns_unique_treshold_4.apply(pd.Series.value_counts)).gt(10).all(1)]\n",
        "\n",
        "df_ads = df_ads[df_ads['f_Tipo proprietà'].notna()]\n",
        "df_ads['c_Tipo proprietà'] = df_ads['f_Tipo proprietà'].str.extract(r\"(Intera proprietà|Multiproprietà|Usufrutto|Diritto di superficie|Parziale proprietà|Nuda proprietà)\", flags = re.IGNORECASE)\n",
        "df_ads['c_Classe proprietà'] = df_ads['f_Tipo proprietà'].str.extract(r\"(classe immobile economica|classe immobile media|classe immobile signorile|immobile di lusso)\", flags = re.IGNORECASE)\n",
        "df_ads['c_Tipo proprietà'] = df_ads['c_Tipo proprietà'].str.lower().str.strip()\n",
        "df_ads['c_Classe proprietà'] = df_ads['c_Classe proprietà'].str.lower().str.strip()\n",
        "df_ads = df_ads[df_ads['c_Tipo proprietà'].notna()]\n",
        "df_ads = df_ads[df_ads['c_Classe proprietà'].notna()]\n",
        "\n",
        "df_ads['f_tipologia'] = df_ads['f_tipologia'].str.lower().str.strip()\n",
        "df_ads = df_ads[df_ads['f_tipologia'].notna()]\n",
        "\n",
        "df_ads['quartiere'] = df_ads['quartiere'].str.lower().str.strip()\n",
        "df_ads = df_ads[df_ads['quartiere'].notna()]\n",
        "\n",
        "df_ads = df_ads[df_ads['f_stato'].notna()]\n",
        "df_ads['c_stato'] = df_ads['f_stato'].str.extract(r\"(Da ristrutturare|Nuovo \\/ In costruzione|Buono \\/ Abitabile|Ottimo \\/ Ristrutturato)\", flags = re.IGNORECASE)\n",
        "df_ads['c_stato'] = df_ads['f_stato'].str.lower().str.strip()\n",
        "df_ads = df_ads[df_ads['c_stato'].notna()]\n",
        "\n",
        "df_ads = df_ads[df_ads['f_Efficienza energetica'].notna()]\n",
        "\n",
        "df_ads['prezzo'] = df_ads['prezzo'].replace('[\\€\\,\\.]', '', regex=True)\n",
        "df_ads['prezzo'] = df_ads['prezzo'].str.extract(r'(\\d+)')\n",
        "df_ads = df_ads[df_ads['prezzo'].notna()]\n",
        "df_ads['prezzo'] = df_ads['prezzo'].astype(int)\n",
        "\n",
        "df_ads['superficie'] = df_ads['superficie'].str.extract(r'(\\d+)')\n",
        "df_ads = df_ads[df_ads['superficie'].notna()]\n",
        "df_ads['superficie'] = df_ads['superficie'].astype(int)\n",
        "\n",
        "df_ads['bagni'] = df_ads['bagni'].str.extract(r'(1|2|3\\+|3)')\n",
        "df_ads['bagni'] = df_ads['bagni'].fillna('0')\n",
        "df_ads['bagni'] = df_ads['bagni'].astype(str)\n",
        "\n",
        "df_ads['locali'] = df_ads['locali'].str.extract(r\"(1|2|3|4|5\\+|5)\")\n",
        "df_ads = df_ads[df_ads['locali'].notna()]\n",
        "df_ads['locali'] = df_ads['locali'].astype(str)\n",
        "\n",
        "df_ads['c_camere da letto'] = df_ads['f_locali'].str.extract(r\"(\\d\\scamer[a,e] da letto)\", flags = re.IGNORECASE)\n",
        "df_ads['c_altri locali'] = df_ads['f_locali'].str.extract(r\"(\\d\\saltr[o,i])\", flags = re.IGNORECASE)\n",
        "\n",
        "df_ads = df_ads[df_ads['c_camere da letto'].notna()]\n",
        "df_ads = df_ads[df_ads['c_altri locali'].notna()]\n",
        "\n",
        "df_ads['c_calcolo numero locali'] = df_ads['c_camere da letto'].str.extract(r\"(\\d)\").astype(int) + df_ads['c_altri locali'].str.extract(r\"(\\d)\").astype(int)\n",
        "\n",
        "df_ads['c_numero totale locali'] = df_ads['locali']\n",
        "df_ads.loc[df_ads['c_numero totale locali'] == '5+', 'c_numero totale locali'] = df_ads['c_calcolo numero locali']\n",
        "df_ads['c_numero totale locali'] = df_ads['c_numero totale locali'].astype(int)\n",
        "\n",
        "df_ads.drop(['c_camere da letto', 'c_altri locali', 'c_calcolo numero locali'], axis=1, inplace=True)\n",
        "\n",
        "df_ads['c_tipo cucina'] = df_ads['f_locali'].str.extract(r\"(cucina abitabile|cucina a vista|cucina angolo cottura|cucina cucinotto|cucina semi abitabile)\", flags = re.IGNORECASE)\n",
        "df_ads['c_tipo cucina'] = df_ads['c_tipo cucina'].str.lower().str.strip().fillna('')\n",
        "\n",
        "df_ads['c_campo da tennis'] = df_ads['f_locali'].str.contains(\"campo da tennis\").astype(int).astype(str)\n",
        "\n",
        "df_ads['f_spese condominio'] = df_ads['f_spese condominio'].str.extract(r'(\\d+)')\n",
        "df_ads['f_spese condominio'] = df_ads['f_spese condominio'].fillna(0)\n",
        "df_ads['f_spese condominio'] = df_ads['f_spese condominio'].astype(int)\n",
        "\n",
        "df_ads['f_totale piani edificio'] = df_ads['f_totale piani edificio'].str.extract(r'(\\d+)')\n",
        "df_ads = df_ads[df_ads['f_totale piani edificio'].notna()]\n",
        "df_ads['f_totale piani edificio'] = df_ads['f_totale piani edificio'].astype(int)\n",
        "df_ads = df_ads[(df_ads['f_totale piani edificio'] < 44)]\n",
        "\n",
        "df_ads = df_ads[df_ads['f_anno di costruzione'].notna()]\n",
        "df_ads['f_anno di costruzione'] = df_ads['f_anno di costruzione'].astype(float).astype(int)\n",
        "\n",
        "df_ads['f_altre caratteristiche'] = df_ads['f_altre caratteristiche'].str.split(',')\n",
        "df_ads['f_altre caratteristiche'] = df_ads['f_altre caratteristiche'].fillna('')\n",
        "\n",
        "df_ads = df_ads[df_ads['prezzo'] < df_ads['prezzo'].quantile(0.999)]\n",
        "df_ads = df_ads[df_ads['prezzo'] > df_ads['prezzo'].quantile(0.0001)]\n",
        "df_ads = df_ads[df_ads['f_Efficienza energetica'].notna()]\n",
        "\n",
        "df_ads['f_Efficienza energetica tipo'] = df_ads['f_Efficienza energetica'].str.extract(r\"(^[A-Z][\\+]?[\\d]?)\", flags = re.IGNORECASE)\n",
        "df_ads['f_Efficienza energetica tipo'] = df_ads['f_Efficienza energetica tipo'].str.upper()\n",
        "df_ads['f_Efficienza energetica tipo'] = df_ads['f_Efficienza energetica tipo'].str.strip()\n",
        "df_ads = df_ads[df_ads['f_Efficienza energetica tipo'].notna()]\n",
        "\n",
        "df_ads['f_Efficienza energetica valore'] = df_ads['f_Efficienza energetica'].str.extract(r\"(\\d+[,]?\\d+)\", flags = re.IGNORECASE)\n",
        "df_ads['f_Efficienza energetica valore'] = df_ads['f_Efficienza energetica valore'].replace('[\\,]', '.', regex=True)\n",
        "df_ads['f_Efficienza energetica valore'] = df_ads['f_Efficienza energetica valore'].str.strip().astype(float)\n",
        "df_ads = df_ads[df_ads['f_Efficienza energetica valore'].notna()]\n",
        "\n",
        "regex_address = \"((?:alzaia|arco|autostrada|belvedere|calata|calle|cavalcavia|circonvallazione|corso|corte|cortile|discesa|foro|galleria|gradinata|larghetto|largo|litoranea|lungargine|lungofiume|lungolago|lungomare|lungoparco|lungotorrente|molo|parcheggio|passaggio|passeggiata|percorso ciclabile|percorso ciclopedonale|percorso pedonale|piazza|piazzale|piazzetta|pista ciclabile|ponte|raccordo|rampa|ripa|ronco|rotatoria|rotonda|salita|scalinata|scesa|sentiero|slargo|sottopasso|sovrappasso|spiazzo|strada|strada antica|strada comunale|strada consortile|strada nuova|strada panoramica|strada poderale|strada privata|strada provinciale|strada regionale|strada statale|strada vecchia|strada vicinale|stradella|stradello|stradone|tangenziale|traversa|traversa privata|via|via antica|via comunale|via nazionale|via nuova|via panoramica|via privata|via provinciale|via vecchia|viale|vialetto|vico|vico chiuso|vico cieco|vico privato|vicoletto|vicolo|vicolo chiuso|vicolo cieco|vicolo privato|viottolo)\\s+[\\d]*[\\u00c4-\\u00e4\\u00d6-\\u00f6-\\u00dc-\\u00fc-\\u00dfa-zA-Z-'\\s\\.]*[,\\s]*[\\d]+[\\w-]*)\"\n",
        "df_ads['indirizzo_2'] = df_ads['titolo'].str.extract(regex_address, flags = re.IGNORECASE)\n",
        "df_ads['indirizzo_2'] = df_ads['indirizzo_2'] + ', milano'\n",
        "df_ads['indirizzo_2'] = df_ads['indirizzo_2'].str.lower().str.strip()\n",
        "df_ads['indirizzo_2'] = df_ads['indirizzo_2'].fillna('')\n",
        "\n",
        "df_ads['g_garage/box'] = df_ads['f_Posti Auto'].str.extract(r\"(\\d\\sin garage\\/box)\", flags = re.IGNORECASE)\n",
        "df_ads['e_all\\'esterno'] = df_ads['f_Posti Auto'].str.extract(r\"(\\d\\sall'esterno)\", flags = re.IGNORECASE)\n",
        "df_ads['g_garage/box'] = df_ads['g_garage/box'].str.extract(r'(\\d+)')\n",
        "df_ads['e_all\\'esterno'] = df_ads['e_all\\'esterno'].str.extract(r'(\\d+)')\n",
        "df_ads['g_garage/box'] = df_ads['g_garage/box'].fillna(0)\n",
        "df_ads['e_all\\'esterno'] = df_ads['e_all\\'esterno'].fillna(0)\n",
        "df_ads['g_garage/box'] = df_ads['g_garage/box'].astype(int)\n",
        "df_ads['e_all\\'esterno'] = df_ads['e_all\\'esterno'].astype(int)\n",
        "df_ads['c_garage number'] = df_ads['g_garage/box'] + df_ads['e_all\\'esterno']\n",
        "\n",
        "df_ads['f_ascensore'] = df_ads['f_piano'].apply(lambda x: '1' if (pd.notna(x) and 'con ascensore' in x) else '0')\n",
        "df_ads['f_disabili'] = df_ads['f_piano'].apply(lambda x: '1' if (pd.notna(x) and 'con accesso disabili' in x) else '0')\n",
        "\n",
        "df_ads['c_Climatizzazione impianto'] = df_ads['f_Climatizzazione'].str.extract(r\"(Autonomo|Centralizzato|Predisposizione impianto)\", flags = re.IGNORECASE)\n",
        "df_ads['c_Climatizzazione impianto'] = df_ads['c_Climatizzazione impianto'].str.lower().str.strip().fillna('')\n",
        "\n",
        "df_ads['c_Climatizzazione tipo'] = df_ads['f_Climatizzazione'].str.extract(r\"(freddo/caldo|freddo|caldo)\", flags = re.IGNORECASE)\n",
        "df_ads['c_Climatizzazione tipo'] = df_ads['c_Climatizzazione tipo'].str.lower().str.strip().fillna('')\n",
        "\n",
        "df_ads['c_riscaldamento impianto'] = df_ads['f_riscaldamento'].str.extract(r\"(Centralizzato|Autonomo)\", flags = re.IGNORECASE)\n",
        "df_ads['c_riscaldamento impianto'] = df_ads['c_riscaldamento impianto'].str.lower().str.strip().fillna('')\n",
        "\n",
        "df_ads['c_riscaldamento tipo'] = df_ads['f_riscaldamento'].str.extract(r\"(a pavimento|a radiatori|ad aria|a stufa)\", flags = re.IGNORECASE)\n",
        "df_ads['c_riscaldamento tipo'] = df_ads['c_riscaldamento tipo'].str.lower().str.strip().fillna('')\n",
        "\n",
        "df_ads['c_riscaldamento alimentazione'] = df_ads['f_riscaldamento'].str.extract(r\"(alimentato a metano|alimentato a gasolio|alimentato a gas|alimentato a pompa di calore|alimentato a gpl|alimentato a teleriscaldamento|alimentazione elettrica|alimentato a fotovoltaico|alimentato a solare|alimentato a pellet)\", flags = re.IGNORECASE)\n",
        "df_ads['c_riscaldamento alimentazione'] = df_ads['c_riscaldamento alimentazione'].str.lower().str.strip().fillna('')\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "df_ads = df_ads.join(\n",
        "  pd.DataFrame(mlb.fit_transform(df_ads.pop('f_altre caratteristiche')),\n",
        "  columns=mlb.classes_,\n",
        "  index=df_ads.index).add_prefix('c_'))\n",
        "\n",
        "columns_caratteristiche = [\n",
        "  'c_Armadio a muro',\n",
        "  'c_Arredato',\n",
        "  'c_Balcone',\n",
        "  'c_Caminetto',\n",
        "  'c_Cancello elettrico',\n",
        "  'c_Cantina',\n",
        "  'c_Cucina',\n",
        "  'c_Esposizione doppia',\n",
        "  'c_Esposizione esterna',\n",
        "  'c_Esposizione interna',\n",
        "  'c_Fibra ottica',\n",
        "  'c_Giardino comune',\n",
        "  'c_Giardino privato',\n",
        "  'c_Idromassaggio',\n",
        "  'c_Impianto di allarme',\n",
        "  'c_Impianto tv centralizzato',\n",
        "  'c_Impianto tv con parabola satellitare',\n",
        "  'c_Impianto tv singolo',\n",
        "  'c_Infissi esterni in doppio vetro / PVC',\n",
        "  'c_Infissi esterni in doppio vetro / legno',\n",
        "  'c_Infissi esterni in doppio vetro / metallo',\n",
        "  'c_Infissi esterni in triplo vetro / PVC',\n",
        "  'c_Infissi esterni in triplo vetro / legno',\n",
        "  'c_Infissi esterni in triplo vetro / metallo',\n",
        "  'c_Infissi esterni in vetro / PVC',\n",
        "  'c_Infissi esterni in vetro / legno',\n",
        "  'c_Infissi esterni in vetro / metallo',\n",
        "  'c_Mansarda',\n",
        "  'c_Parzialmente Arredato',\n",
        "  'c_Piscina',\n",
        "  'c_Porta blindata',\n",
        "  'c_Portiere intera giornata',\n",
        "  'c_Portiere mezza giornata',\n",
        "  'c_Reception',\n",
        "  'c_Solo Cucina Arredata',\n",
        "  'c_Taverna',\n",
        "  'c_Terrazza',\n",
        "  'c_VideoCitofono'\n",
        "]\n",
        "\n",
        "df_ads[columns_caratteristiche] = df_ads[columns_caratteristiche].astype(str)\n",
        "\n",
        "df_ads = df_ads.drop('titolo', axis=1)\n",
        "df_ads = df_ads.drop('indirizzo', axis=1)\n",
        "df_ads = df_ads.drop('f_locali', axis=1)\n",
        "df_ads = df_ads.drop('f_piano', axis=1)\n",
        "df_ads = df_ads.drop('f_Tipo proprietà', axis=1)\n",
        "df_ads = df_ads.drop('f_tipologia', axis=1)\n",
        "df_ads = df_ads.drop('f_stato', axis=1)\n",
        "df_ads = df_ads.drop('f_Climatizzazione', axis=1)\n",
        "df_ads = df_ads.drop('f_riscaldamento', axis=1)\n",
        "df_ads = df_ads.drop('f_Posti Auto', axis=1)\n",
        "df_ads = df_ads.drop('f_Efficienza energetica', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tydS4Hg5dQ5_"
      },
      "source": [
        "df_ads.info()\n",
        "display(df_ads.describe().transpose())\n",
        "display(df_ads.head(5).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gAH6CfdaQ9G"
      },
      "source": [
        "csv_ads_clean = 'Ads_clean_' + get_timestamp() + '.csv'\n",
        "df_ads.to_csv(csv_ads_clean, index=False)\n",
        "files.download(csv_ads_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_whek-wTtDv"
      },
      "source": [
        "dictionary = {}\n",
        "column = 'c_tipo cucina'\n",
        "sum = 0\n",
        "for index, row in df_ads_columns.iterrows():\n",
        "  cell = row[column]\n",
        "  sum += 1\n",
        "  if not cell in dictionary:\n",
        "    dictionary[cell] = 1\n",
        "  else:\n",
        "    dictionary[cell] += 1\n",
        "\n",
        "print(sum)\n",
        "\n",
        "print(sorted(dictionary.items(), key=lambda x:x[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G3lJkVdG6H7"
      },
      "source": [
        "## Geocoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3VmPckNxCXo"
      },
      "source": [
        "from geopy import distance"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60rJhPVkuDws"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBgOVZbxuDw2"
      },
      "source": [
        "csv_ads_clean = 'Ads_clean_1618605615.csv'\n",
        "df_ads_geo = pd.read_csv(csv_ads_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uss1PKBJWksz"
      },
      "source": [
        "geolocator = Nominatim(user_agent='myGeocoder')\n",
        "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "df_ads_geo = df_ads.copy()\n",
        "\n",
        "df_ads_geo['indirizzo_geocode'] = df_ads_geo['indirizzo_2'].progress_apply(geocode)\n",
        "df_ads_geo['point'] = df_ads_geo['indirizzo_geocode'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
        "df_ads_geo[['latitude', 'longitude', 'altitude']] = pd.DataFrame(df_ads_geo['point'].tolist(), index=df_ads_geo.index)\n",
        "\n",
        "#df_ads_geo.drop('indirizzo_geocode', axis=1)\n",
        "#df_ads_geo.drop('point', axis=1)\n",
        "#df_ads_geo.drop('altitude', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmVKGAuyJbhc"
      },
      "source": [
        "csv_ads_geo = 'Ads_geo_1618621216.csv'\n",
        "df_ads_geo = pd.read_csv(csv_ads_geo)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ifxAoowwDR"
      },
      "source": [
        "DUOMO_DI_MILANO = (45.4641, 9.1919)\n",
        "CASTELLO_SFORZESCO = (45.4704, 9.1793)\n",
        "GALLERIA_VITTORIO_EMANUALE_II = (45.4658, 9.1899)\n",
        "TEATRO_LA_SCALA = (45.4674, 9.1895)\n",
        "ARCO_DELLA_PACE = (45.4756, 9.1724)\n",
        "\n",
        "def calc_distance(from_loc, to_lat, to_long):\n",
        "  if not math.isnan(to_lat) and not math.isnan(to_long):\n",
        "    return round(float(distance.distance(from_loc, (to_lat, to_long)).km), 3)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "def get_distance(df, column_name, from_location):\n",
        "  df[column_name] = df.apply(lambda row: calc_distance(from_location, row.latitude, row.longitude), axis=1)\n",
        "  return df\n",
        "\n",
        "df_ads_geo = get_distance(df_ads_geo, 'distance_duomo', DUOMO_DI_MILANO)\n",
        "df_ads_geo = get_distance(df_ads_geo, 'distance_castello', CASTELLO_SFORZESCO)\n",
        "df_ads_geo = get_distance(df_ads_geo, 'distance_galleria', GALLERIA_VITTORIO_EMANUALE_II)\n",
        "df_ads_geo = get_distance(df_ads_geo, 'distance_scala', TEATRO_LA_SCALA)\n",
        "df_ads_geo = get_distance(df_ads_geo, 'distance_arco', ARCO_DELLA_PACE)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_yrM8qY5An"
      },
      "source": [
        "df_ads_geo.info()\n",
        "display(df_ads_geo.describe().transpose())\n",
        "display(df_ads_geo.head(5).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6bIOZNMY5Ay"
      },
      "source": [
        "csv_ads_geo = 'Ads_geo_' + get_timestamp() + '.csv'\n",
        "df_ads_geo.to_csv(csv_ads_geo, index=False)\n",
        "files.download(csv_ads_geo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkpwkeWLvOFd"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfZ6tyatFGYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d27885-e2fa-4733-9b98-5404d43ec416"
      },
      "source": [
        "!pip install dython\n",
        "\n",
        "import dython\n",
        "from dython.nominal import correlation_ratio\n",
        "from dython.nominal import associations\n",
        "\n",
        "!which python\n",
        "!python --version\n",
        "!echo $PYTHONPATH\n",
        "%env PYTHONPATH=\n",
        "\n",
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n",
        "\n",
        "!which conda\n",
        "!conda --version\n",
        "!which python\n",
        "!python --version\n",
        "\n",
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes\n",
        "conda update --channel defaults --all --yes\n",
        "\n",
        "!conda --version\n",
        "!python --version\n",
        "\n",
        "sys.path\n",
        "\n",
        "!ls /usr/local/lib/python3.7/dist-packages\n",
        "\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.7/site-packages\"))\n",
        "\n",
        "!conda install -c conda-forge ipywidgets --yes\n",
        "!conda install -c conda-forge gmaps --yes\n",
        "\n",
        "import gmaps\n",
        "import gmaps.datasets "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::asn1crypto==0.24.0=py36_0\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - ipywidgets\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    argon2-cffi-20.1.0         |   py37h4abf009_2          47 KB  conda-forge\n",
            "    asn1crypto-1.4.0           |     pyh9f0ad1d_0          78 KB  conda-forge\n",
            "    async_generator-1.10       |             py_0          18 KB  conda-forge\n",
            "    attrs-20.3.0               |     pyhd3deb0d_0          41 KB  conda-forge\n",
            "    backcall-0.2.0             |     pyh9f0ad1d_0          13 KB  conda-forge\n",
            "    backports-1.0              |             py_2           4 KB  conda-forge\n",
            "    backports.functools_lru_cache-1.6.4|     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    bleach-3.3.0               |     pyh44b312d_0         111 KB  conda-forge\n",
            "    ca-certificates-2020.12.5  |       ha878542_0         137 KB  conda-forge\n",
            "    certifi-2020.12.5          |   py37h89c1867_1         143 KB  conda-forge\n",
            "    conda-4.10.1               |   py37h89c1867_0         3.1 MB  conda-forge\n",
            "    decorator-5.0.7            |     pyhd8ed1ab_0          11 KB  conda-forge\n",
            "    defusedxml-0.7.1           |     pyhd8ed1ab_0          23 KB  conda-forge\n",
            "    entrypoints-0.3            |  pyhd8ed1ab_1003           8 KB  conda-forge\n",
            "    importlib-metadata-3.10.1  |   py37h89c1867_0          27 KB  conda-forge\n",
            "    ipykernel-5.5.3            |   py37h085eea5_0         166 KB  conda-forge\n",
            "    ipython-7.22.0             |   py37h085eea5_0         1.1 MB  conda-forge\n",
            "    ipython_genutils-0.2.0     |             py_1          21 KB  conda-forge\n",
            "    ipywidgets-7.6.3           |     pyhd3deb0d_0         101 KB  conda-forge\n",
            "    jedi-0.18.0                |   py37h89c1867_2         923 KB  conda-forge\n",
            "    jinja2-2.11.3              |     pyh44b312d_0          93 KB  conda-forge\n",
            "    jsonschema-3.2.0           |     pyhd8ed1ab_3          45 KB  conda-forge\n",
            "    jupyter_client-6.1.12      |     pyhd8ed1ab_0          79 KB  conda-forge\n",
            "    jupyter_core-4.7.1         |   py37h89c1867_0          72 KB  conda-forge\n",
            "    jupyterlab_pygments-0.1.2  |     pyh9f0ad1d_0           8 KB  conda-forge\n",
            "    jupyterlab_widgets-1.0.0   |     pyhd8ed1ab_1         130 KB  conda-forge\n",
            "    libsodium-1.0.18           |       h36c2ea0_1         366 KB  conda-forge\n",
            "    markupsafe-1.1.1           |   py37hb5d75c8_2          27 KB  conda-forge\n",
            "    mistune-0.8.4              |py37h4abf009_1002          54 KB  conda-forge\n",
            "    nbclient-0.5.3             |     pyhd8ed1ab_0          67 KB  conda-forge\n",
            "    nbconvert-6.0.7            |   py37h89c1867_3         535 KB  conda-forge\n",
            "    nbformat-5.1.3             |     pyhd8ed1ab_0          47 KB  conda-forge\n",
            "    nest-asyncio-1.5.1         |     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    notebook-6.3.0             |     pyha770c72_1         6.1 MB  conda-forge\n",
            "    packaging-20.9             |     pyh44b312d_0          35 KB  conda-forge\n",
            "    pandoc-2.12                |       h7f98852_0        12.4 MB  conda-forge\n",
            "    pandocfilters-1.4.2        |             py_1           9 KB  conda-forge\n",
            "    parso-0.8.2                |     pyhd8ed1ab_0          68 KB  conda-forge\n",
            "    pexpect-4.8.0              |     pyh9f0ad1d_2          47 KB  conda-forge\n",
            "    pickleshare-0.7.5          |          py_1003           9 KB  conda-forge\n",
            "    prometheus_client-0.10.1   |     pyhd8ed1ab_0          46 KB  conda-forge\n",
            "    prompt-toolkit-3.0.18      |     pyha770c72_0         244 KB  conda-forge\n",
            "    ptyprocess-0.7.0           |     pyhd3deb0d_0          16 KB  conda-forge\n",
            "    pygments-2.8.1             |     pyhd8ed1ab_0         736 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    pyrsistent-0.17.3          |   py37h4abf009_1          89 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pyzmq-19.0.2               |   py37hac76be4_2         471 KB  conda-forge\n",
            "    send2trash-1.5.0           |             py_0          12 KB  conda-forge\n",
            "    terminado-0.9.4            |   py37h89c1867_0          26 KB  conda-forge\n",
            "    testpath-0.4.4             |             py_0          85 KB  conda-forge\n",
            "    tornado-6.1                |   py37h4abf009_0         645 KB  conda-forge\n",
            "    traitlets-5.0.5            |             py_0          81 KB  conda-forge\n",
            "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
            "    wcwidth-0.2.5              |     pyh9f0ad1d_2          33 KB  conda-forge\n",
            "    webencodings-0.5.1         |             py_1          12 KB  conda-forge\n",
            "    widgetsnbextension-3.5.1   |   py37h89c1867_4         1.8 MB  conda-forge\n",
            "    zeromq-4.3.4               |       h2531618_0         331 KB\n",
            "    zipp-3.4.1                 |     pyhd8ed1ab_0          11 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        31.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  argon2-cffi        conda-forge/linux-64::argon2-cffi-20.1.0-py37h4abf009_2\n",
            "  async_generator    conda-forge/noarch::async_generator-1.10-py_0\n",
            "  attrs              conda-forge/noarch::attrs-20.3.0-pyhd3deb0d_0\n",
            "  backcall           conda-forge/noarch::backcall-0.2.0-pyh9f0ad1d_0\n",
            "  backports          conda-forge/noarch::backports-1.0-py_2\n",
            "  backports.functoo~ conda-forge/noarch::backports.functools_lru_cache-1.6.4-pyhd8ed1ab_0\n",
            "  bleach             conda-forge/noarch::bleach-3.3.0-pyh44b312d_0\n",
            "  decorator          conda-forge/noarch::decorator-5.0.7-pyhd8ed1ab_0\n",
            "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0\n",
            "  entrypoints        conda-forge/noarch::entrypoints-0.3-pyhd8ed1ab_1003\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-3.10.1-py37h89c1867_0\n",
            "  ipykernel          conda-forge/linux-64::ipykernel-5.5.3-py37h085eea5_0\n",
            "  ipython            conda-forge/linux-64::ipython-7.22.0-py37h085eea5_0\n",
            "  ipython_genutils   conda-forge/noarch::ipython_genutils-0.2.0-py_1\n",
            "  ipywidgets         conda-forge/noarch::ipywidgets-7.6.3-pyhd3deb0d_0\n",
            "  jedi               conda-forge/linux-64::jedi-0.18.0-py37h89c1867_2\n",
            "  jinja2             conda-forge/noarch::jinja2-2.11.3-pyh44b312d_0\n",
            "  jsonschema         conda-forge/noarch::jsonschema-3.2.0-pyhd8ed1ab_3\n",
            "  jupyter_client     conda-forge/noarch::jupyter_client-6.1.12-pyhd8ed1ab_0\n",
            "  jupyter_core       conda-forge/linux-64::jupyter_core-4.7.1-py37h89c1867_0\n",
            "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.1.2-pyh9f0ad1d_0\n",
            "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-1.0.0-pyhd8ed1ab_1\n",
            "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1\n",
            "  markupsafe         conda-forge/linux-64::markupsafe-1.1.1-py37hb5d75c8_2\n",
            "  mistune            conda-forge/linux-64::mistune-0.8.4-py37h4abf009_1002\n",
            "  nbclient           conda-forge/noarch::nbclient-0.5.3-pyhd8ed1ab_0\n",
            "  nbconvert          conda-forge/linux-64::nbconvert-6.0.7-py37h89c1867_3\n",
            "  nbformat           conda-forge/noarch::nbformat-5.1.3-pyhd8ed1ab_0\n",
            "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.1-pyhd8ed1ab_0\n",
            "  notebook           conda-forge/noarch::notebook-6.3.0-pyha770c72_1\n",
            "  packaging          conda-forge/noarch::packaging-20.9-pyh44b312d_0\n",
            "  pandoc             conda-forge/linux-64::pandoc-2.12-h7f98852_0\n",
            "  pandocfilters      conda-forge/noarch::pandocfilters-1.4.2-py_1\n",
            "  parso              conda-forge/noarch::parso-0.8.2-pyhd8ed1ab_0\n",
            "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh9f0ad1d_2\n",
            "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003\n",
            "  prometheus_client  conda-forge/noarch::prometheus_client-0.10.1-pyhd8ed1ab_0\n",
            "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.18-pyha770c72_0\n",
            "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0\n",
            "  pygments           conda-forge/noarch::pygments-2.8.1-pyhd8ed1ab_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  pyrsistent         conda-forge/linux-64::pyrsistent-0.17.3-py37h4abf009_1\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pyzmq              conda-forge/linux-64::pyzmq-19.0.2-py37hac76be4_2\n",
            "  send2trash         conda-forge/noarch::send2trash-1.5.0-py_0\n",
            "  terminado          conda-forge/linux-64::terminado-0.9.4-py37h89c1867_0\n",
            "  testpath           conda-forge/noarch::testpath-0.4.4-py_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py37h4abf009_0\n",
            "  traitlets          conda-forge/noarch::traitlets-5.0.5-py_0\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
            "  wcwidth            conda-forge/noarch::wcwidth-0.2.5-pyh9f0ad1d_2\n",
            "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
            "  widgetsnbextension conda-forge/linux-64::widgetsnbextension-3.5.1-py37h89c1867_4\n",
            "  zeromq             pkgs/main/linux-64::zeromq-4.3.4-h2531618_0\n",
            "  zipp               conda-forge/noarch::zipp-3.4.1-pyhd8ed1ab_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-0.24.0~ --> conda-forge/noarch::asn1crypto-1.4.0-pyh9f0ad1d_0\n",
            "  certifi            pkgs/main::certifi-2020.12.5-py37h06a~ --> conda-forge::certifi-2020.12.5-py37h89c1867_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2021.4.13-~ --> conda-forge::ca-certificates-2020.12.5-ha878542_0\n",
            "  conda              pkgs/main::conda-4.10.1-py37h06a4308_1 --> conda-forge::conda-4.10.1-py37h89c1867_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "certifi-2020.12.5    | 143 KB    | : 100% 1.0/1 [00:00<00:00,  5.09it/s]                \n",
            "ipykernel-5.5.3      | 166 KB    | : 100% 1.0/1 [00:00<00:00,  7.78it/s]\n",
            "widgetsnbextension-3 | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.33it/s]\n",
            "send2trash-1.5.0     | 12 KB     | : 100% 1.0/1 [00:00<00:00, 21.89it/s]\n",
            "python-dateutil-2.8. | 220 KB    | : 100% 1.0/1 [00:00<00:00, 13.70it/s]\n",
            "pygments-2.8.1       | 736 KB    | : 100% 1.0/1 [00:00<00:00,  2.88it/s]\n",
            "nest-asyncio-1.5.1   | 9 KB      | : 100% 1.0/1 [00:00<00:00, 25.68it/s]\n",
            "pyrsistent-0.17.3    | 89 KB     | : 100% 1.0/1 [00:00<00:00, 14.02it/s]\n",
            "ipywidgets-7.6.3     | 101 KB    | : 100% 1.0/1 [00:00<00:00, 14.45it/s]\n",
            "jupyterlab_pygments- | 8 KB      | : 100% 1.0/1 [00:00<00:00, 19.02it/s]\n",
            "pandocfilters-1.4.2  | 9 KB      | : 100% 1.0/1 [00:00<00:00, 20.29it/s]\n",
            "argon2-cffi-20.1.0   | 47 KB     | : 100% 1.0/1 [00:00<00:00, 17.00it/s]\n",
            "jupyter_client-6.1.1 | 79 KB     | : 100% 1.0/1 [00:00<00:00, 12.64it/s]\n",
            "pandoc-2.12          | 12.4 MB   | : 100% 1.0/1 [00:05<00:00,  5.52s/it]\n",
            "pyparsing-2.4.7      | 60 KB     | : 100% 1.0/1 [00:00<00:00, 19.85it/s]\n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 26.33it/s]\n",
            "typing_extensions-3. | 25 KB     | : 100% 1.0/1 [00:00<00:00, 21.05it/s]\n",
            "nbconvert-6.0.7      | 535 KB    | : 100% 1.0/1 [00:00<00:00,  4.30it/s]\n",
            "importlib-metadata-3 | 27 KB     | : 100% 1.0/1 [00:00<00:00, 24.12it/s]\n",
            "zipp-3.4.1           | 11 KB     | : 100% 1.0/1 [00:00<00:00, 21.92it/s]\n",
            "tornado-6.1          | 645 KB    | : 100% 1.0/1 [00:00<00:00,  3.12it/s]\n",
            "markupsafe-1.1.1     | 27 KB     | : 100% 1.0/1 [00:00<00:00, 19.39it/s]\n",
            "pexpect-4.8.0        | 47 KB     | : 100% 1.0/1 [00:00<00:00, 17.86it/s]\n",
            "prometheus_client-0. | 46 KB     | : 100% 1.0/1 [00:00<00:00, 19.51it/s]\n",
            "jupyter_core-4.7.1   | 72 KB     | : 100% 1.0/1 [00:00<00:00, 15.89it/s]\n",
            "asn1crypto-1.4.0     | 78 KB     | : 100% 1.0/1 [00:00<00:00, 15.08it/s]\n",
            "backports.functools_ | 9 KB      | : 100% 1.0/1 [00:00<00:00, 23.85it/s]\n",
            "nbformat-5.1.3       | 47 KB     | : 100% 1.0/1 [00:00<00:00, 15.54it/s]\n",
            "conda-4.10.1         | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.05it/s]\n",
            "backcall-0.2.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 21.44it/s]\n",
            "jupyterlab_widgets-1 | 130 KB    | : 100% 1.0/1 [00:00<00:00,  8.72it/s]\n",
            "attrs-20.3.0         | 41 KB     | : 100% 1.0/1 [00:00<00:00, 22.60it/s]\n",
            "entrypoints-0.3      | 8 KB      | : 100% 1.0/1 [00:00<00:00, 23.16it/s]\n",
            "jsonschema-3.2.0     | 45 KB     | : 100% 1.0/1 [00:00<00:00, 20.27it/s]\n",
            "testpath-0.4.4       | 85 KB     | : 100% 1.0/1 [00:00<00:00, 18.67it/s]\n",
            "bleach-3.3.0         | 111 KB    | : 100% 1.0/1 [00:00<00:00, 12.61it/s]\n",
            "zeromq-4.3.4         | 331 KB    | : 100% 1.0/1 [00:00<00:00,  5.44it/s]                \n",
            "defusedxml-0.7.1     | 23 KB     | : 100% 1.0/1 [00:00<00:00, 19.50it/s]\n",
            "webencodings-0.5.1   | 12 KB     | : 100% 1.0/1 [00:00<00:00, 25.01it/s]\n",
            "parso-0.8.2          | 68 KB     | : 100% 1.0/1 [00:00<00:00, 15.65it/s]\n",
            "traitlets-5.0.5      | 81 KB     | : 100% 1.0/1 [00:00<00:00, 12.73it/s]\n",
            "packaging-20.9       | 35 KB     | : 100% 1.0/1 [00:00<00:00, 16.73it/s]\n",
            "terminado-0.9.4      | 26 KB     | : 100% 1.0/1 [00:00<00:00, 24.74it/s]\n",
            "notebook-6.3.0       | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.94s/it]\n",
            "mistune-0.8.4        | 54 KB     | : 100% 1.0/1 [00:00<00:00, 15.38it/s]\n",
            "ipython-7.22.0       | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.02it/s]\n",
            "wcwidth-0.2.5        | 33 KB     | : 100% 1.0/1 [00:00<00:00, 17.56it/s]\n",
            "jinja2-2.11.3        | 93 KB     | : 100% 1.0/1 [00:00<00:00, 14.84it/s]\n",
            "prompt-toolkit-3.0.1 | 244 KB    | : 100% 1.0/1 [00:00<00:00,  6.98it/s]\n",
            "async_generator-1.10 | 18 KB     | : 100% 1.0/1 [00:00<00:00, 17.21it/s]\n",
            "nbclient-0.5.3       | 67 KB     | : 100% 1.0/1 [00:00<00:00, 17.43it/s]\n",
            "libsodium-1.0.18     | 366 KB    | : 100% 1.0/1 [00:00<00:00,  8.50it/s]\n",
            "jedi-0.18.0          | 923 KB    | : 100% 1.0/1 [00:00<00:00,  1.43it/s]\n",
            "ptyprocess-0.7.0     | 16 KB     | : 100% 1.0/1 [00:00<00:00, 23.27it/s]\n",
            "decorator-5.0.7      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 26.48it/s]\n",
            "ca-certificates-2020 | 137 KB    | : 100% 1.0/1 [00:00<00:00, 16.94it/s]\n",
            "backports-1.0        | 4 KB      | : 100% 1.0/1 [00:00<00:00, 29.33it/s]\n",
            "pickleshare-0.7.5    | 9 KB      | : 100% 1.0/1 [00:00<00:00, 28.32it/s]\n",
            "pyzmq-19.0.2         | 471 KB    | : 100% 1.0/1 [00:00<00:00,  3.92it/s]\n",
            "ipython_genutils-0.2 | 21 KB     | : 100% 1.0/1 [00:00<00:00, 20.44it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| Enabling notebook extension jupyter-js-widgets/extension...\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.d/plotlywidget.json\n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.json\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.d/plotlywidget.json\n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.d/plotlywidget.json\n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\n",
            "    \t/usr/local/etc/jupyter/nbconfig/notebook.json\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - gmaps\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    geojson-2.5.0              |             py_0          15 KB  conda-forge\n",
            "    gmaps-0.9.0                |             py_0         1.7 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         1.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  geojson            conda-forge/noarch::geojson-2.5.0-py_0\n",
            "  gmaps              conda-forge/noarch::gmaps-0.9.0-py_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "geojson-2.5.0        | 15 KB     | : 100% 1.0/1 [00:00<00:00,  8.77it/s]\n",
            "gmaps-0.9.0          | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.28it/s]\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41eaqJsw9PMy"
      },
      "source": [
        "gmaps.configure(api_key='AIzaSyApxgN3Or1iJYsM8h7Z2BtWxu-k5_siXxw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToriAx-cW3Sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7a0f38-37fd-4a0d-f6b4-492dc8aa2e85"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB3Q4k5tW3Sm"
      },
      "source": [
        "csv_ads_clean = 'Ads_clean_1618568380.csv'\n",
        "df_ads_clean = pd.read_csv(csv_ads_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5_w0Csr6K3T"
      },
      "source": [
        "df_ads_clean = df_ads_geo"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dktaBa2IW3So"
      },
      "source": [
        "df_ads_clean.info()\n",
        "display(df_ads_clean.describe().transpose())\n",
        "display(df_ads_clean.head(5).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88EQMeAVJ9MY"
      },
      "source": [
        "#list(df_ads_clean.columns.values)\n",
        "#df_ads_clean.dtypes\n",
        "\n",
        "columns_filtered = [\n",
        "  'prezzo',\n",
        "  'quartiere',\n",
        "  'superficie',\n",
        "  'bagni',\n",
        "  #'piano',\n",
        "  'locali',\n",
        "  'f_totale piani edificio',\n",
        "  'f_spese condominio',\n",
        "  'f_anno di costruzione',\n",
        "  'c_Tipo proprietà',\n",
        "  'c_Classe proprietà',\n",
        "  'c_stato',\n",
        "  'c_numero totale locali',\n",
        "  'c_tipo cucina',\n",
        "  'c_campo da tennis',\n",
        "  'f_Efficienza energetica tipo',\n",
        "  'f_Efficienza energetica valore',\n",
        "  'g_garage/box',\n",
        "  \"e_all'esterno\",\n",
        "  'c_garage number',\n",
        "  'f_ascensore',\n",
        "  'f_disabili',\n",
        "  'c_Climatizzazione impianto',\n",
        "  'c_Climatizzazione tipo',\n",
        "  'c_riscaldamento impianto',\n",
        "  'c_riscaldamento tipo',\n",
        "  'c_riscaldamento alimentazione',\n",
        "  'c_Armadio a muro',\n",
        "  'c_Arredato',\n",
        "  'c_Balcone',\n",
        "  'c_Caminetto',\n",
        "  'c_Cancello elettrico',\n",
        "  'c_Cantina',\n",
        "  'c_Cucina',\n",
        "  'c_Esposizione doppia',\n",
        "  'c_Esposizione esterna',\n",
        "  'c_Esposizione interna',\n",
        "  'c_Fibra ottica',\n",
        "  'c_Giardino comune',\n",
        "  'c_Giardino privato',\n",
        "  'c_Idromassaggio',\n",
        "  'c_Impianto di allarme',\n",
        "  'c_Impianto tv centralizzato',\n",
        "  'c_Impianto tv con parabola satellitare',\n",
        "  'c_Impianto tv singolo',\n",
        "  'c_Infissi esterni in doppio vetro / PVC',\n",
        "  'c_Infissi esterni in doppio vetro / legno',\n",
        "  'c_Infissi esterni in doppio vetro / metallo',\n",
        "  'c_Infissi esterni in triplo vetro / PVC',\n",
        "  'c_Infissi esterni in triplo vetro / legno',\n",
        "  'c_Infissi esterni in triplo vetro / metallo',\n",
        "  'c_Infissi esterni in vetro / PVC',\n",
        "  'c_Infissi esterni in vetro / legno',\n",
        "  'c_Infissi esterni in vetro / metallo',\n",
        "  'c_Mansarda',\n",
        "  'c_Parzialmente Arredato',\n",
        "  'c_Piscina',\n",
        "  'c_Porta blindata',\n",
        "  'c_Portiere intera giornata',\n",
        "  'c_Portiere mezza giornata',\n",
        "  'c_Reception',\n",
        "  'c_Solo Cucina Arredata',\n",
        "  'c_Taverna',\n",
        "  'c_Terrazza',\n",
        "  'c_VideoCitofono',\n",
        "  'distance_duomo',\n",
        "  'distance_castello',\n",
        "  'distance_galleria',\n",
        "  'distance_scala',\n",
        "  'distance_arco'\n",
        "]\n",
        "\n",
        "columns_nominal = [\n",
        "  'quartiere',\n",
        "  'bagni',\n",
        "  'locali',\n",
        "  'c_Tipo proprietà',\n",
        "  'c_Classe proprietà',\n",
        "  'c_stato',\n",
        "  'c_tipo cucina',\n",
        "  'c_campo da tennis',\n",
        "  'f_Efficienza energetica tipo',\n",
        "  'f_ascensore',\n",
        "  'f_disabili',\n",
        "  'c_Climatizzazione impianto',\n",
        "  'c_Climatizzazione tipo',\n",
        "  'c_riscaldamento impianto',\n",
        "  'c_riscaldamento tipo',\n",
        "  'c_riscaldamento alimentazione',\n",
        "  'c_Armadio a muro',\n",
        "  'c_Arredato',\n",
        "  'c_Balcone',\n",
        "  'c_Caminetto',\n",
        "  'c_Cancello elettrico',\n",
        "  'c_Cantina',\n",
        "  'c_Cucina',\n",
        "  'c_Esposizione doppia',\n",
        "  'c_Esposizione esterna',\n",
        "  'c_Esposizione interna',\n",
        "  'c_Fibra ottica',\n",
        "  'c_Giardino comune',\n",
        "  'c_Giardino privato',\n",
        "  'c_Idromassaggio',\n",
        "  'c_Impianto di allarme',\n",
        "  'c_Impianto tv centralizzato',\n",
        "  'c_Impianto tv con parabola satellitare',\n",
        "  'c_Impianto tv singolo',\n",
        "  'c_Infissi esterni in doppio vetro / PVC',\n",
        "  'c_Infissi esterni in doppio vetro / legno',\n",
        "  'c_Infissi esterni in doppio vetro / metallo',\n",
        "  'c_Infissi esterni in triplo vetro / PVC',\n",
        "  'c_Infissi esterni in triplo vetro / legno',\n",
        "  'c_Infissi esterni in triplo vetro / metallo',\n",
        "  'c_Infissi esterni in vetro / PVC',\n",
        "  'c_Infissi esterni in vetro / legno',\n",
        "  'c_Infissi esterni in vetro / metallo',\n",
        "  'c_Mansarda',\n",
        "  'c_Parzialmente Arredato',\n",
        "  'c_Piscina',\n",
        "  'c_Porta blindata',\n",
        "  'c_Portiere intera giornata',\n",
        "  'c_Portiere mezza giornata',\n",
        "  'c_Reception',\n",
        "  'c_Solo Cucina Arredata',\n",
        "  'c_Taverna',\n",
        "  'c_Terrazza',\n",
        "  'c_VideoCitofono'\n",
        "]\n",
        "\n",
        "ADS_FILTERED = True\n",
        "\n",
        "if ADS_FILTERED:\n",
        "  #df_ads_clean_alias = df_ads_clean[df_ads_clean['c_Classe proprietà'] == 'classe immobile signorile']\n",
        "  df_ads_clean_alias = df_ads_clean[df_ads_clean.point.notnull()]\n",
        "else:\n",
        "  df_ads_clean_alias = df_ads_clean.copy()\n",
        "\n",
        "df_ads_clean_alias = df_ads_clean_alias[columns_filtered].copy()\n",
        "\n",
        "print(len(df_ads_clean_alias.index))\n",
        "\n",
        "associations_dictionary = associations(df_ads_clean_alias, nan_strategy='replace', nan_replace_value='', nominal_columns=columns_nominal, figsize=(50, 50), cmap='seismic', mark_columns=True)\n",
        "\n",
        "associations_corr = associations_dictionary['corr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaTzDnoviJNU"
      },
      "source": [
        "corr_threshold = 0.15\n",
        "\n",
        "corr_price = associations_corr['prezzo (con)']\n",
        "corr_price_filtered = corr_price[(corr_price >= corr_threshold) | (corr_price <= corr_threshold * -1)]\n",
        "\n",
        "display(corr_price_filtered.sort_values(ascending = False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fS5zmo-d5lV"
      },
      "source": [
        "corr_graph = associations_corr[(associations_corr >= corr_threshold) | (associations_corr <= corr_threshold * -1)]\n",
        "\n",
        "plt.figure(figsize=(50, 50))\n",
        "sb.heatmap(corr_graph, cmap=\"Greens\", square=True, vmin=0, vmax=1, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecH_2IaUJLp1"
      },
      "source": [
        "df_ads_clean.hist(figsize = (50, 50))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daOxBTbM5z31"
      },
      "source": [
        "def scatter_df(df, var_x, var_y):\n",
        "  scatter_df = df.drop(var_y, axis = 1)\n",
        "  \n",
        "  df_columns = df.columns\n",
        "  \n",
        "  plt.subplots(figsize=(15, 12))\n",
        "  scatterplot = sb.scatterplot(x = var_x, y = var_y, data = df, hue='c_Classe proprietà')\n",
        "  \n",
        "  plt.title('{} / prezzo'.format(var_x))\n",
        "\n",
        "  plt.xlabel('{}'.format(var_x))\n",
        "  plt.ylabel(var_y)\n",
        "\n",
        "var_x = 'superficie'\n",
        "var_y = 'prezzo'\n",
        "\n",
        "scatter_df(df_ads_clean, var_x, var_y)\n",
        "\n",
        "print(len(df_ads_clean[df_ads_clean['c_Classe proprietà'] == 'classe immobile signorile'].index))\n",
        "print(len(df_ads_clean[df_ads_clean['c_Classe proprietà'] == 'classe immobile media'].index))\n",
        "print(len(df_ads_clean[df_ads_clean['c_Classe proprietà'] == 'classe immobile economica'].index))\n",
        "print(len(df_ads_clean[df_ads_clean['c_Classe proprietà'] == 'immobile di lusso'].index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph1wPtLpFe0J"
      },
      "source": [
        "fig_dims = (25, 10)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "plt.xlim(0, 5000000)\n",
        "\n",
        "sb.histplot(df_ads_clean['prezzo'], ax=ax)\n",
        "\n",
        "plt.title('Prezzo')\n",
        "\n",
        "plt.xlabel('Prezzo')\n",
        "plt.ylabel('Frequency')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JW6B6ccB9Jg"
      },
      "source": [
        "fig_dims = (25, 10)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "sb.boxplot(x=df_ads_clean['prezzo'], ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "e8e93c76e1a547888033dfc09c57141c"
          ]
        },
        "id": "CijWi2Pj8M7-",
        "outputId": "f080bfb3-8167-4a3d-dabb-6b5e9b2cd29f"
      },
      "source": [
        "df_ads_clean_2 = df_ads_clean[df_ads_clean.point.notnull()]\n",
        "locations = df_ads_clean_2[['latitude', 'longitude']]\n",
        "fig = gmaps.figure()\n",
        "locations\n",
        "fig.add_layer(gmaps.heatmap_layer(locations))\n",
        "fig"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e93c76e1a547888033dfc09c57141c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Figure(layout=FigureLayout(height='420px'))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z38bhe1xKDwO"
      },
      "source": [
        "## Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7bzRGJiKONV"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqEId5Nja8Wf"
      },
      "source": [
        "### One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAowODQYazE6"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC27mfDQciCK"
      },
      "source": [
        "csv_ads_clean = 'Ads_clean_1618601583.csv'\n",
        "df_ads_clean = pd.read_csv(csv_ads_clean)\n",
        "df_ads_hot = df_ads_clean.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONt23TB_vW7"
      },
      "source": [
        "'''\n",
        "prezzo (con)                        1.000000\n",
        "c_Cucina (nom)                      0.612992\n",
        "c_Climatizzazione impianto (nom)    0.352175\n",
        "c_Climatizzazione tipo (nom)        0.280697\n",
        "c_Esposizione esterna (nom)         0.266680\n",
        "quartiere (nom)                     0.227998\n",
        "c_Impianto di allarme (nom)         0.226017\n",
        "c_Esposizione interna (nom)         0.204731\n",
        "superficie (con)                    0.183167\n",
        "c_stato (nom)                       0.175994\n",
        "locali (nom)                        0.175958\n",
        "f_disabili (nom)                    0.175493\n",
        "c_numero totale locali (con)        0.173612\n",
        "'''\n",
        "\n",
        "columns_filtered = [\n",
        "  'prezzo',\n",
        "  'quartiere',\n",
        "  'superficie',\n",
        "  'bagni',\n",
        "  #'piano',\n",
        "  'locali',\n",
        "  'f_totale piani edificio',\n",
        "  'f_spese condominio',\n",
        "  'f_anno di costruzione',\n",
        "  'c_Tipo proprietà',\n",
        "  'c_Classe proprietà',\n",
        "  'c_stato',\n",
        "  'c_numero totale locali',\n",
        "  'c_tipo cucina',\n",
        "  'c_campo da tennis',\n",
        "  'f_Efficienza energetica tipo',\n",
        "  'f_Efficienza energetica valore',\n",
        "  'g_garage/box',\n",
        "  \"e_all'esterno\",\n",
        "  'c_garage number',\n",
        "  'f_ascensore',\n",
        "  'f_disabili',\n",
        "  'c_Climatizzazione impianto',\n",
        "  'c_Climatizzazione tipo',\n",
        "  'c_riscaldamento impianto',\n",
        "  'c_riscaldamento tipo',\n",
        "  'c_riscaldamento alimentazione',\n",
        "  'c_Armadio a muro',\n",
        "  'c_Arredato',\n",
        "  'c_Balcone',\n",
        "  'c_Caminetto',\n",
        "  'c_Cancello elettrico',\n",
        "  'c_Cantina',\n",
        "  'c_Cucina',\n",
        "  'c_Esposizione doppia',\n",
        "  'c_Esposizione esterna',\n",
        "  'c_Esposizione interna',\n",
        "  'c_Fibra ottica',\n",
        "  'c_Giardino comune',\n",
        "  'c_Giardino privato',\n",
        "  'c_Idromassaggio',\n",
        "  'c_Impianto di allarme',\n",
        "  'c_Impianto tv centralizzato',\n",
        "  'c_Impianto tv con parabola satellitare',\n",
        "  'c_Impianto tv singolo',\n",
        "  'c_Infissi esterni in doppio vetro / PVC',\n",
        "  'c_Infissi esterni in doppio vetro / legno',\n",
        "  'c_Infissi esterni in doppio vetro / metallo',\n",
        "  'c_Infissi esterni in triplo vetro / PVC',\n",
        "  'c_Infissi esterni in triplo vetro / legno',\n",
        "  'c_Infissi esterni in triplo vetro / metallo',\n",
        "  'c_Infissi esterni in vetro / PVC',\n",
        "  'c_Infissi esterni in vetro / legno',\n",
        "  'c_Infissi esterni in vetro / metallo',\n",
        "  'c_Mansarda',\n",
        "  'c_Parzialmente Arredato',\n",
        "  'c_Piscina',\n",
        "  'c_Porta blindata',\n",
        "  'c_Portiere intera giornata',\n",
        "  'c_Portiere mezza giornata',\n",
        "  'c_Reception',\n",
        "  'c_Solo Cucina Arredata',\n",
        "  'c_Taverna',\n",
        "  'c_Terrazza',\n",
        "  'c_VideoCitofono'\n",
        "]\n",
        "\n",
        "df_ads_hot = df_ads_hot.filter(items=columns_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGI1TySZKxa5"
      },
      "source": [
        "dummies_dict = {\n",
        "  ('c_Climatizzazione tipo', 'ct'),\n",
        "  ('locali', 'l'),\n",
        "  ('bagni', 'b'),\n",
        "  ('quartiere', 'q'),\n",
        "  ('c_tipo cucina', 'tc'),\n",
        "  ('c_Classe proprietà', 'cp'),\n",
        "  ('f_Efficienza energetica tipo', 'eet'),\n",
        "  ('c_Tipo proprietà', 'tp'),\n",
        "  #('piano', 'p'),\n",
        "  ('c_stato', 's'),\n",
        "  ('c_Climatizzazione impianto', 'ci'),\n",
        "  ('c_riscaldamento impianto', 'ri'),\n",
        "  ('c_riscaldamento tipo', 'rt'),\n",
        "  ('c_riscaldamento alimentazione', 'ra')\n",
        "}\n",
        "\n",
        "def dummies(df, dummies_dict):\n",
        "  for column in dummies_dict:\n",
        "    df = pd.concat([df, pd.get_dummies(df[column[0]], prefix=column[1])], axis=1)\n",
        "    df.drop([column[0]], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "df_ads_hot = dummies(df_ads_hot, dummies_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmWVvIM6t_P5"
      },
      "source": [
        "print(df_ads_hot.info())\n",
        "display(df_ads_hot.describe().transpose())\n",
        "display(df_ads_hot.head(10).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcf_Qmtvd2v_"
      },
      "source": [
        "csv_ads_hot = 'Ads_hot_' + get_timestamp() + '.csv'\n",
        "df_ads_hot.to_csv(csv_ads_hot, index=False)\n",
        "files.download(csv_ads_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sFiJjLRbC5_"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz9IaKQfnhJo"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PosLc-Qsg7na"
      },
      "source": [
        "csv_ads_hot = 'Ads_hot_1618568534.csv'\n",
        "df_ads_hot = pd.read_csv(csv_ads_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xhfID4A6Ig7"
      },
      "source": [
        "cols = df_ads_hot.columns\n",
        "for col in cols:\n",
        "  df_ads_hot[col] = df_ads_hot[col].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t833wdFaWrPV"
      },
      "source": [
        "df_ads_hot.info()\n",
        "display(df_ads_hot.describe().transpose())\n",
        "display(df_ads_hot.head(10).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi5kWKUD-DDN"
      },
      "source": [
        "df_ads_hot = df_ads_hot[df_ads_hot['cp_classe immobile signorile'] == 1]\n",
        "df_ads_hot = df_ads_hot[df_ads_hot['prezzo'] < 500000]\n",
        "print(len(df_ads_hot.index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwRNzhhJKXmv"
      },
      "source": [
        "train, val, test = np.split(df_ads_hot.sample(frac=1), [int(.8*len(df_ads_hot)), int(.9*len(df_ads_hot))])\n",
        "\n",
        "X_train = train.drop('prezzo', axis=1)\n",
        "Y_train = train[['prezzo']]\n",
        "\n",
        "X_val = val.drop('prezzo', axis=1)\n",
        "Y_val = val[['prezzo']]\n",
        "\n",
        "X_test = test.drop('prezzo', axis=1)\n",
        "Y_test = test[['prezzo']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXCg5lq2WQge"
      },
      "source": [
        "columns_standard = ['superficie', 'f_totale piani edificio', 'f_spese condominio', 'f_anno di costruzione', 'g_garage/box', 'e_all\\'esterno', 'c_garage number', 'c_numero totale locali', 'f_Efficienza energetica valore']\n",
        "\n",
        "ct_data = ColumnTransformer(transformers = [('ct_data', StandardScaler(), columns_standard)], remainder ='passthrough')\n",
        "ct_target = StandardScaler()\n",
        "\n",
        "X_train_scaled = ct_data.fit_transform(X_train)\n",
        "Y_train_scaled = ct_target.fit_transform(Y_train)\n",
        "\n",
        "X_val_scaled = ct_data.fit_transform(X_val)\n",
        "Y_val_scaled = ct_target.fit_transform(Y_val)\n",
        "\n",
        "X_test_scaled = ct_data.fit_transform(X_test)\n",
        "Y_test_scaled = ct_target.fit_transform(Y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bffk-c-kKHZr"
      },
      "source": [
        "model = Sequential()\n",
        " \n",
        "model.add(Dense(1024, kernel_initializer='normal', input_dim = X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(1024, kernel_initializer='normal', input_dim = X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(1024, kernel_initializer='normal', input_dim = X_train_scaled.shape[1], activation='relu'))\n",
        " \n",
        "model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
        " \n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPin-sdJLy6B"
      },
      "source": [
        "history = model.fit(X_train_scaled, Y_train_scaled, epochs=50, batch_size=32, validation_data = (X_val_scaled, Y_val_scaled))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGWMKq4ZolCG"
      },
      "source": [
        "  plt.figure(figsize=(15, 10))\n",
        "\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Mean Absolute Error [€]')\n",
        "\n",
        "  plt.plot(history.epoch, np.array(history.history['mean_squared_error']), label='Train Loss')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mean_squared_error']), label = 'Val Loss')\n",
        "\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxao6mKMn6aS"
      },
      "source": [
        "model.evaluate(X_test_scaled, Y_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM-H2kDFoclV"
      },
      "source": [
        "Y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "Y_pred = pd.Series(map(lambda x: x[0], Y_pred))\n",
        "Y_pred_inverse = ct_target.inverse_transform(Y_pred)\n",
        "\n",
        "Y_test_inverse = pd.Series(map(lambda x: x[0], Y_test_scaled))\n",
        "Y_test_inverse = ct_target.inverse_transform(Y_test_inverse)\n",
        "\n",
        "df_ads_pred = pd.DataFrame({ 'Actual': Y_test_inverse, 'Predicted': Y_pred_inverse }).astype('int64')\n",
        "df_ads_pred['Error'] = abs(df_ads_pred['Actual'] - df_ads_pred['Predicted'])\n",
        "df_ads_pred['%'] = (df_ads_pred['Error'] * 100 / df_ads_pred['Actual'])\n",
        "\n",
        "df_ads_pred = df_ads_pred.sort_values(by=['%'])\n",
        "\n",
        "#display(df_ads_pred)\n",
        "\n",
        "print(str(int(round(df_ads_pred['Error'].mean()))) + '€')\n",
        "print(str(int(round(df_ads_pred['%'].mean()))) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhxCw_0Q_Fdj"
      },
      "source": [
        "print('MAE:', metrics.mean_absolute_error(Y_test_inverse, Y_pred_inverse))\n",
        "print('MSE:', metrics.mean_squared_error(Y_test_inverse, Y_pred_inverse))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test_inverse, Y_pred_inverse)))\n",
        "print('VarScore:', metrics.explained_variance_score(Y_test_inverse, Y_pred_inverse))\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.scatter(Y_test_inverse, Y_pred_inverse)\n",
        "\n",
        "plt.plot(Y_test_inverse, Y_test_inverse, 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7QixXL_yeh"
      },
      "source": [
        "residuals = (Y_test - Y_pred)\n",
        "sb.displot(residuals)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}