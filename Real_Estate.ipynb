{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real Estate.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WqlSQgeUPRY8",
        "7zttfFhGC5oG",
        "XxA68wOAP0l2",
        "HYwkMUp_v0ky"
      ],
      "toc_visible": true,
      "mount_file_id": "1A-y6uCmxkJSunVdJCwrECF4F7mEa4muq",
      "authorship_tag": "ABX9TyPsDvwVEHvensQbWzNJV//G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreabazerla/real-estate/blob/main/Real_Estate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxX68uAbjv4j"
      },
      "source": [
        "# Housing Price Prediction in Milan (Italy) through Deep Learning via immobiliare.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ehFWpWmwkL"
      },
      "source": [
        "<img src=\"https://media.giphy.com/media/gTURHJs4e2Ies/source.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp788-zijJ5_"
      },
      "source": [
        "# Web Scraping: immobiliare.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqlSQgeUPRY8"
      },
      "source": [
        "## IP Address"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8ekOcm2PYj4"
      },
      "source": [
        "print('Google Colab IP Address = ', end='')\n",
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JsUJVgFPOqY"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub9J4KGqPTlV"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import math\n",
        "from google.colab import files\n",
        "import requests\n",
        "from enum import Enum \n",
        "from random import uniform\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ULYiXW0m-U"
      },
      "source": [
        "## Environment variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4IVwi70dIw"
      },
      "source": [
        "PRODUCTION = True"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5xuHKjXQj57"
      },
      "source": [
        "## Pandas Options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2E31Y_ltpbT"
      },
      "source": [
        "pd.option_context('display.max_rows', None, 'display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eo5A1b0PUqR"
      },
      "source": [
        "## Enums"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTs8ZzrGrMV7"
      },
      "source": [
        "class Contract(Enum):\n",
        "  VENDITA = 'vendita'\n",
        "  AFFITTO = 'affitto'\n",
        " \n",
        "class Area(Enum):\n",
        "  MILANO = 'milano'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKuBB1xBPYuo"
      },
      "source": [
        "## URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHhqN9p1pp89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be14aa6e-1559-4ab0-cd80-e6e34684c97f"
      },
      "source": [
        "slash = '/'\n",
        "https = 'https://'\n",
        "website = 'www.immobiliare.it'\n",
        "contract = Contract.VENDITA.value + '-case'\n",
        "area = Area.MILANO.value\n",
        "sort = '?criterio=rilevanza'\n",
        " \n",
        "url = https + website + slash + contract + slash + area + slash + sort\n",
        " \n",
        "print('url = ' + url)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "url = https://www.immobiliare.it/vendita-case/milano/?criterio=rilevanza\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0F3Ipv1Pbv5"
      },
      "source": [
        "## Sleep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sDTxZLWoypo"
      },
      "source": [
        "sleep_min = 1\n",
        "sleep_max = 30\n",
        " \n",
        "def get_timeout(min, max):\n",
        "  return uniform(min, max)\n",
        " \n",
        "def sleep_random_range(min, max, verbose):\n",
        "  timeout = get_timeout(min, max)\n",
        "  if (verbose): print('Sleep ' + str(int(timeout)) + 's...')\n",
        "  time.sleep(timeout)\n",
        " \n",
        "def sleep():\n",
        "  sleep_random_range(sleep_min, sleep_max, False)\n",
        " \n",
        "def get_sleep_list(number_pages):\n",
        "  sleep_list = []\n",
        "  while(number_pages):\n",
        "    sleep_list.append(get_timeout(sleep_min, sleep_max))\n",
        "    number_pages -= 1\n",
        "  return sleep_list, sum(sleep_list)\n",
        " \n",
        "def sleep_time(timeout):\n",
        "  time.sleep(timeout)\n",
        " \n",
        "def sec_to_time(seconds):\n",
        "  return str(datetime.timedelta(seconds=seconds))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hldwisi3Pj2k"
      },
      "source": [
        "## Ads Link List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWPHL4GhPeL4"
      },
      "source": [
        "### Get Last Page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujp1eEaWqpda"
      },
      "source": [
        "def get_last_page(url):\n",
        "  sleep()\n",
        "  \n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  \n",
        "    ul_pagination = soup.find(\"ul\", class_ = \"pagination pagination__number\")\n",
        "    li_list = ul_pagination.find_all(\"li\")\n",
        "    last_page = int(li_list[-1].get_text().strip())\n",
        "  \n",
        "    return last_page\n",
        "  \n",
        "  except requests.exceptions.RequestException as e:\n",
        "    raise SystemExit(e)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4n2yjyf1FAf"
      },
      "source": [
        "### Get Ads Links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAvqYAvLTwe"
      },
      "source": [
        "def get_ads_link_list(url, first_page, last_page):\n",
        "  ads_link_list = []\n",
        "  \n",
        "  pag = first_page  \n",
        "  \n",
        "  number_pages = last_page - first_page + 1\n",
        "  \n",
        "  sleep_list, sum_sleep_list = get_sleep_list(number_pages)\n",
        "  print('Total sleep time = ' + sec_to_time(int(sum_sleep_list)))\n",
        " \n",
        "  if (len(sleep_list) != number_pages):\n",
        "    raise Exception(\"Sleep time list not equal to number of pages to analyse\")\n",
        "  \n",
        "  idx = 0\n",
        "  while (pag <= last_page):\n",
        "    if (pag > 1):\n",
        "      url = url + '&pag=' + str(pag)\n",
        "    \n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "      soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    \n",
        "      ads_list = soup.find('ul', class_ = 'annunci-list')\n",
        "      ad_item_list = ads_list.find_all('div', class_ = 'listing-item_body--content')\n",
        "      for ad_item in ad_item_list:\n",
        "        a_list = ad_item.find_all(\"a\")\n",
        "        for a in a_list:\n",
        "          href = a[\"href\"]\n",
        "          ads_link_list.append(href)\n",
        "    \n",
        "    except:\n",
        "      continue\n",
        "    \n",
        "    pag += 1\n",
        " \n",
        "    #print('Sleep ' + str(int(sleep_list[idx])) + 's...')\n",
        "    sleep_time(sleep_list[idx])\n",
        "    idx += 1\n",
        "  \n",
        "  return ads_link_list"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds-RxO8FRWJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632a5855-70d7-46ec-8c58-6070c271bfd4"
      },
      "source": [
        "if PRODUCTION:\n",
        "  first_page = 1\n",
        "  last_page = 3\n",
        "  #last_page = get_last_page(url)\n",
        "  ads_link_list = get_ads_link_list(url, first_page, last_page)\n",
        "  ads_link_list = list(dict.fromkeys(ads_link_list))\n",
        "  print('Total number of ads = ' + str(len(ads_link_list)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sleep time = 0:00:50\n",
            "Total number of ads = 75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zttfFhGC5oG"
      },
      "source": [
        "### Print Ads Links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyXAiq8P5Nmo"
      },
      "source": [
        "for idx, ad_link in enumerate(ads_link_list, start=1):\n",
        "    print(str(idx) + '\\t' + ad_link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVh8OIbPrDI"
      },
      "source": [
        "### Store Ads Links to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRYgjfjwTaZD"
      },
      "source": [
        "df_links = pd.DataFrame({'Links' : list(ads_link_list)})\n",
        "\n",
        "csv_links = 'Links_' + str(int(time.time())) + '_' + str(first_page) + '_' + str(last_page) + '.csv'\n",
        "df_links.to_csv(csv_links, index=False)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxA68wOAP0l2"
      },
      "source": [
        "### Read Ads Links from CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouxt67hjV5pO"
      },
      "source": [
        "df_links = pd.read_csv(csv_links)\n",
        "ads_link_list = df_links['Links'].to_list()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVcqqV_mIP_v"
      },
      "source": [
        "#### Print Ads Links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geHFh7YrSE8Z"
      },
      "source": [
        "for idx, item in enumerate(ads_link_list, start=1):\n",
        "    print(str(idx) + '\\t' + item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYJChvNAHltT"
      },
      "source": [
        "### Display Links CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "J1-miVRuHolW",
        "outputId": "a9103a84-bf9b-4f52-fd2b-0a1b0951d431"
      },
      "source": [
        "display(df_links)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.immobiliare.it/annunci/p-159766/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.immobiliare.it/annunci/68088357/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.immobiliare.it/annunci/84184532/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.immobiliare.it/annunci/p-157721/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.immobiliare.it/annunci/85213731/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>https://www.immobiliare.it/annunci/84904534/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>https://www.immobiliare.it/annunci/83378181/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>https://www.immobiliare.it/annunci/82445950/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>https://www.immobiliare.it/annunci/86790348/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>https://www.immobiliare.it/annunci/86234056/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Links\n",
              "0   https://www.immobiliare.it/annunci/p-159766/\n",
              "1   https://www.immobiliare.it/annunci/68088357/\n",
              "2   https://www.immobiliare.it/annunci/84184532/\n",
              "3   https://www.immobiliare.it/annunci/p-157721/\n",
              "4   https://www.immobiliare.it/annunci/85213731/\n",
              "..                                           ...\n",
              "70  https://www.immobiliare.it/annunci/84904534/\n",
              "71  https://www.immobiliare.it/annunci/83378181/\n",
              "72  https://www.immobiliare.it/annunci/82445950/\n",
              "73  https://www.immobiliare.it/annunci/86790348/\n",
              "74  https://www.immobiliare.it/annunci/86234056/\n",
              "\n",
              "[75 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYwkMUp_v0ky"
      },
      "source": [
        "### Download Link CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoV65WKTvsgT"
      },
      "source": [
        "files.download(csv_links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66tYwTTjP4ly"
      },
      "source": [
        "## Ad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uom11OKPP8sV"
      },
      "source": [
        "### Ad Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykpkKlkZogG3"
      },
      "source": [
        "def get_ad_title(soup):\n",
        "  titleBlock__title = soup.find('span', class_ = 'im-titleBlock__title')\n",
        "  return titleBlock__title.get_text()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKnLtSIsQA5Y"
      },
      "source": [
        "### Ad Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb-N84mK6Ipm"
      },
      "source": [
        "def get_ad_price(soup):\n",
        "  mainFeatures__price = soup.find_all('li', class_ = 'im-mainFeatures__price')\n",
        "  return mainFeatures__price[0].get_text().replace('\\n', '').strip()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQui5M3KQDZg"
      },
      "source": [
        "### Ad Main Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwAGku2_5V1"
      },
      "source": [
        "def get_ad_main_feature(soup):\n",
        "  main_features = {}\n",
        "  \n",
        "  mainFeatures = soup.find('div', class_ = 'im-mainFeatures')\n",
        "  \n",
        "  li_list = mainFeatures.find_all('li')\n",
        "  for li in li_list[1:]:\n",
        "    value = li.find('span', class_=\"im-mainFeatures__value\").get_text().replace('\\n', '').strip()\n",
        "    label = li.find('span', class_=\"im-mainFeatures__label\").get_text().replace('\\n', '').strip()\n",
        "    \n",
        "    if (label == 'bagno' or label == 'bagni'):\n",
        "      label = 'bagni'\n",
        "    \n",
        "    if (label == 'locale' or label == 'locali'):\n",
        "      label = 'locali'\n",
        "    \n",
        "    main_features[label] = value\n",
        "  \n",
        "  return main_features"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onVN270MQHLw"
      },
      "source": [
        "### Ad Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgHNdLhX23BI"
      },
      "source": [
        "def get_ad_description(soup):\n",
        "  description__text = soup.find('div', class_ = 'im-description__text')\n",
        "  return description__text.get_text()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA3RXVP-QKIb"
      },
      "source": [
        "### Ad Locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0-tj0Geel2"
      },
      "source": [
        "def get_ad_locations(soup):\n",
        "  location_list = []\n",
        "  \n",
        "  titleBlock__link = soup.find('a', class_ = 'im-titleBlock__link')\n",
        "  location = titleBlock__link.find_all('span', class_ = 'im-location')\n",
        "  \n",
        "  try:\n",
        "    area = location[0].get_text().strip()\n",
        "  except IndexError:\n",
        "    area = ''\n",
        "  \n",
        "  try:\n",
        "    district = location[1].get_text().strip()\n",
        "  except IndexError:\n",
        "    district = ''\n",
        "\n",
        "  try:\n",
        "    address = location[2].get_text().strip()\n",
        "  except IndexError:\n",
        "    address = ''\n",
        "\n",
        "  return [area, district, address]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnDT1ZSOQNDd"
      },
      "source": [
        "### Ad Feature List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhuVyk5h_Kfb"
      },
      "source": [
        "def get_ad_feature_list(soup):\n",
        "  features = {}\n",
        "  \n",
        "  features__list = soup.find_all(\"dl\", class_ = \"im-features__list\")\n",
        "  \n",
        "  for feature_block in features__list:\n",
        "    feature__title_list = feature_block.find_all('dt', class_ = 'im-features__title')\n",
        "  \n",
        "    for feature__title in feature__title_list:\n",
        "      feature__value = feature__title.findNext('dd')\n",
        "  \n",
        "      if ('im-features__tagContainer' in feature__value.get('class')):\n",
        "        features__tag_array = []\n",
        "\n",
        "        features__tag_list = soup.find_all('span', class_ = 'im-features__tag')\n",
        "        for feature__tag in features__tag_list:\n",
        "          features__tag_array.append(feature__tag.get_text().strip())\n",
        "  \n",
        "        features__tag_list_string = ','.join(features__tag_array)\n",
        "        feature__value_2 = features__tag_list_string\n",
        "  \n",
        "      else:\n",
        "        feature__value_2 = feature__value.get_text().strip()\n",
        "  \n",
        "      feature__title_2 = feature__title.get_text().strip()\n",
        "      features['f_' + feature__title_2] = feature__value_2\n",
        "  \n",
        "  return features"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAw9UTlzQQkZ"
      },
      "source": [
        "### Ad Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLEg4LNxGf9L"
      },
      "source": [
        "def get_ad(url):\n",
        "  if 'p-' in url:\n",
        "    return get_ad_multi(url)\n",
        "  else:\n",
        "    return get_ad_single(url)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OWffZz4QWWw"
      },
      "source": [
        "### Ad Single"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILWk45lM2V27"
      },
      "source": [
        "def get_ad_single(url):\n",
        "  ads_list = []\n",
        "  ad_data = {}\n",
        "\n",
        "  ad_data['url'] = url\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    title = get_ad_title(soup);\n",
        "    ad_data['titolo'] = title\n",
        "\n",
        "    price = get_ad_price(soup);\n",
        "    ad_data['prezzo'] = price\n",
        "\n",
        "    main_features = get_ad_main_feature(soup)\n",
        "    if main_features:\n",
        "      ad_data.update(main_features)\n",
        "\n",
        "    description = get_ad_description(soup);\n",
        "    ad_data['descrizione'] = description\n",
        "\n",
        "    area, district, address = get_ad_locations(soup)\n",
        "    ad_data['area'] = area\n",
        "    ad_data['quartiere'] = district\n",
        "    ad_data['indirizzo'] = address\n",
        "\n",
        "    feature_list = get_ad_feature_list(soup)\n",
        "    if feature_list:\n",
        "      ad_data.update(feature_list)\n",
        "\n",
        "    ad_data['hashcode'] = hash(frozenset(ad_data.items()))\n",
        "\n",
        "    ads_list.append(ad_data)\n",
        "  \n",
        "  except Exception as e:\n",
        "    logging.exception(' '.join(url, e))\n",
        "    pass\n",
        "\n",
        "  return ads_list"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtrLpzqcQb5f"
      },
      "source": [
        "### Ad Multi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOCb5naQ2IML"
      },
      "source": [
        "def get_ad_multi(url):\n",
        "  ads_list = []\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    title = get_ad_title(soup);\n",
        "\n",
        "    area, district, address = get_ad_locations(soup)\n",
        "\n",
        "    main_features = get_ad_main_feature(soup)\n",
        "\n",
        "    description = get_ad_description(soup)\n",
        "\n",
        "    feature_list = get_ad_feature_list(soup)\n",
        "\n",
        "    properties__list = soup.find('ul', class_ = 'im-properties__list')\n",
        "    properties__item_list = properties__list.find_all('li', class_ = 'im-properties__item')\n",
        "    for properties__item in properties__item_list:\n",
        "      ad_data = {}\n",
        "\n",
        "      ad_data['url'] = url\n",
        "\n",
        "      ad_data['titolo'] = title\n",
        "\n",
        "      ad_data['area'] = area\n",
        "      ad_data['quartiere'] = district\n",
        "      ad_data['indirizzo'] = address\n",
        "      \n",
        "      price = get_ad_price(properties__item)\n",
        "      ad_data['prezzo'] = price\n",
        "\n",
        "      ad_data['descrizione'] = description\n",
        "\n",
        "      sub_features = get_ad_main_feature(properties__item)\n",
        "      if sub_features:\n",
        "        ad_data.update(sub_features)\n",
        "\n",
        "      title_2 = properties__item.find('p', class_ = 'nd-mediaObject__title').get_text().strip()\n",
        "      ad_data['titolo_2'] = title_2\n",
        "\n",
        "      description_2 = properties__item.find('div', class_ = 'im-properties__content').get_text()\n",
        "      ad_data['descrizione_2'] = description_2\n",
        "\n",
        "      if feature_list:\n",
        "        ad_data.update(feature_list)\n",
        "\n",
        "      ad_data['hashcode'] = hash(frozenset(ad_data.items()))\n",
        "\n",
        "      ads_list.append(ad_data)\n",
        "\n",
        "  except Exception as e:\n",
        "    logging.exception(e)\n",
        "    pass\n",
        "  \n",
        "  return ads_list"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5smqhCWQfD2"
      },
      "source": [
        "### Ads Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DnnXijuFbWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ebe3b5-57d5-43a3-ab7a-ff46ffd144d3"
      },
      "source": [
        "if PRODUCTION:\n",
        "  df = pd.DataFrame()\n",
        "\n",
        "  first_ad = 0\n",
        "  last_ad = 15\n",
        "  #last_ad = len(ads_link_list)\n",
        "\n",
        "  number_ads = last_ad - first_ad\n",
        "  block_size = 3\n",
        "  number_files = math.ceil(number_ads / block_size)\n",
        "  ads_rest = number_ads % block_size\n",
        "\n",
        "  timestamp = str(int(time.time()))\n",
        "  ads_folder = 'Ads_' + timestamp + '_' + str(first_ad) + '_' + str(last_ad)\n",
        "\n",
        "  if not os.path.exists(ads_folder):\n",
        "    os.makedirs(ads_folder)\n",
        "\n",
        "  sleep_list, sum_sleep_list = get_sleep_list(number_ads)\n",
        "  print('Total sleep time = ' + sec_to_time(int(sum_sleep_list)))\n",
        "  if (len(sleep_list) != number_ads):\n",
        "    raise Exception(\"Sleep time list not equal to number of ads to scrape\")\n",
        "\n",
        "  ads_list = []\n",
        "  ads_list_block = []\n",
        "  column_list = []\n",
        "  index_file = 0\n",
        "  for i in range(number_ads):\n",
        "\n",
        "    ad_data = get_ad(ads_link_list[i])\n",
        "    for ad in ad_data:\n",
        "      ads_list.append(ad)\n",
        "      ads_list_block.append(ad)\n",
        "\n",
        "    if ((i > 0 and i % block_size == 0) or i == last_ad - 1):\n",
        "      df_block = pd.DataFrame(ads_list_block)\n",
        "      df_block.fillna('', inplace=True)\n",
        "      csv_ads = 'Ads_' + timestamp\n",
        "      df_block.to_csv(ads_folder + '/' + csv_ads + '_' + str(index_file) + '.csv', index=False)\n",
        "      index_file += 1\n",
        "      ads_list_block = []\n",
        "    \n",
        "    sleep_time(sleep_list[i])\n",
        "  \n",
        "  df = pd.DataFrame(ads_list)\n",
        "  df.fillna('', inplace=True)\n",
        "  df.to_csv('Ads_' + timestamp + '_' + str(first_ad) + '_' + str(last_ad - 1) + '.csv', index=False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sleep time = 0:03:03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj5iDlC3QpyI"
      },
      "source": [
        "### Display Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D11eWCH2Qe2w"
      },
      "source": [
        "  display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn4nE_EhwzCF"
      },
      "source": [
        "### Download Ads .zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8kJUzgNwywE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c616715-c775-4cb7-bcc8-dd0514358e15"
      },
      "source": [
        "!zip -r {ads_folder}.zip {ads_folder}\n",
        "files.download(ads_folder + '.zip')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: Ads_1616767025_0_7/ (stored 0%)\n",
            "  adding: Ads_1616767025_0_7/Ads_1616767025_6_9_1.csv (deflated 88%)\n",
            "  adding: Ads_1616767025_0_7/Ads_1616767025_3_6_0.csv (deflated 76%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_709163c6-e87d-485c-bdc1-7cf4f38d6eb0\", \"Ads_1616767025_0_7.zip\", 10132)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ZlVubdvkpy"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    }
  ]
}