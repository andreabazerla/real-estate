{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real Estate.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bYJChvNAHltT"
      ],
      "toc_visible": true,
      "mount_file_id": "https://gist.github.com/andreabazerla/2b71bb337708c231b6d9d741973dfa46#file-real-estate-ipynb",
      "authorship_tag": "ABX9TyO9e48hTAR9SgT/uRrQcOCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreabazerla/real-estate/blob/main/Real_Estate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxX68uAbjv4j"
      },
      "source": [
        "# Housing Price Prediction in Milan (Italy) through Deep Learning via immobiliare.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ehFWpWmwkL"
      },
      "source": [
        "<img src=\"https://media.giphy.com/media/gTURHJs4e2Ies/source.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp788-zijJ5_"
      },
      "source": [
        "# Web Scraping: immobiliare.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqlSQgeUPRY8"
      },
      "source": [
        "## IP Address"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8ekOcm2PYj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a609949a-3284-4ebd-ce7b-90e4b72a6da1"
      },
      "source": [
        "print('Google Colab IP Address = ', end='')\n",
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Google Colab IP Address = 35.188.3.232"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JsUJVgFPOqY"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub9J4KGqPTlV"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import math\n",
        "from google.colab import files\n",
        "import requests\n",
        "from enum import Enum \n",
        "from random import uniform\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ULYiXW0m-U"
      },
      "source": [
        "## Environment variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4IVwi70dIw"
      },
      "source": [
        "PRODUCTION = True\n",
        "GET_ADS_LINKS = False\n",
        "GET_ADS_LIST = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5xuHKjXQj57"
      },
      "source": [
        "## Pandas Options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2E31Y_ltpbT"
      },
      "source": [
        "pd.option_context('display.max_rows', None, 'display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eo5A1b0PUqR"
      },
      "source": [
        "## Enums"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTs8ZzrGrMV7"
      },
      "source": [
        "class Contract(Enum):\n",
        "  VENDITA = 'vendita'\n",
        "  AFFITTO = 'affitto'\n",
        " \n",
        "class Area(Enum):\n",
        "  MILANO = 'milano'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKuBB1xBPYuo"
      },
      "source": [
        "## URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHhqN9p1pp89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677b2f42-bb71-4979-8943-883cf26e6879"
      },
      "source": [
        "slash = '/'\n",
        "https = 'https://'\n",
        "website = 'www.immobiliare.it'\n",
        "contract = Contract.VENDITA.value + '-case'\n",
        "area = Area.MILANO.value\n",
        "sort = '?criterio=rilevanza'\n",
        " \n",
        "url = https + website + slash + contract + slash + area + slash + sort\n",
        " \n",
        "print('url = ' + url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "url = https://www.immobiliare.it/vendita-case/milano/?criterio=rilevanza\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0F3Ipv1Pbv5"
      },
      "source": [
        "## Sleep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sDTxZLWoypo"
      },
      "source": [
        "sleep_min = 3\n",
        "sleep_max = 5\n",
        "\n",
        "def sleep_default():\n",
        "  time.sleep(uniform(sleep_min, sleep_max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hldwisi3Pj2k"
      },
      "source": [
        "## Ads Link List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWPHL4GhPeL4"
      },
      "source": [
        "### Get Last Page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujp1eEaWqpda"
      },
      "source": [
        "def get_last_page(url):\n",
        "  sleep_default()\n",
        "  \n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  \n",
        "    ul_pagination = soup.find(\"ul\", class_ = \"pagination pagination__number\")\n",
        "    li_list = ul_pagination.find_all(\"li\")\n",
        "    last_page = int(li_list[-1].get_text().strip())\n",
        "  \n",
        "    return last_page\n",
        "  \n",
        "  except requests.exceptions.RequestException as e:\n",
        "    raise SystemExit(e)\n",
        "\n",
        "#last_page = get_last_page(url)\n",
        "#print('Last page = ' + str(last_page))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4n2yjyf1FAf"
      },
      "source": [
        "### Get Ads Links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAvqYAvLTwe"
      },
      "source": [
        "def get_ads_link_list(url, first_page, last_page):\n",
        "  ads_link_list = []\n",
        "  \n",
        "  pag = first_page\n",
        "  \n",
        "  while (pag <= last_page):\n",
        "    if (pag > 1):\n",
        "      url = url + '&pag=' + str(pag)\n",
        "    \n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "\n",
        "      soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    \n",
        "      ads_list = soup.find('ul', class_ = 'annunci-list')\n",
        "      ad_item_list = ads_list.find_all('div', class_ = 'listing-item_body--content')\n",
        "      for ad_item in ad_item_list:\n",
        "        a_list = ad_item.find_all(\"a\")\n",
        "        for a in a_list:\n",
        "          href = a[\"href\"]\n",
        "          ads_link_list.append(href)\n",
        "    \n",
        "    except Exception as e:\n",
        "      logging.exception(e)\n",
        "      print(str(pag))\n",
        "      pass\n",
        "    \n",
        "    pag += 1\n",
        " \n",
        "    sleep_default()\n",
        "  \n",
        "  return ads_link_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds-RxO8FRWJp"
      },
      "source": [
        "if PRODUCTION:\n",
        "  if GET_ADS_LINKS:\n",
        "    first_page = 1\n",
        "    #last_page = 631\n",
        "    last_page = get_last_page(url)\n",
        "  \n",
        "    ads_link_list = get_ads_link_list(url, first_page, last_page)\n",
        "    ads_link_list = list(dict.fromkeys(ads_link_list))\n",
        "    \n",
        "    print('Total number of ads = ' + str(len(ads_link_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVh8OIbPrDI"
      },
      "source": [
        "### Store Ads Links to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRYgjfjwTaZD"
      },
      "source": [
        "df_links = pd.DataFrame({'Links' : list(ads_link_list)})\n",
        "\n",
        "csv_links = 'Links_' + str(int(time.time())) + '_' + str(first_page) + '_' + str(last_page) + '.csv'\n",
        "df_links.to_csv(csv_links, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYJChvNAHltT"
      },
      "source": [
        "### Display Links CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-miVRuHolW"
      },
      "source": [
        "display(df_links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYwkMUp_v0ky"
      },
      "source": [
        "### Download Link CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoV65WKTvsgT"
      },
      "source": [
        "files.download(csv_links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66tYwTTjP4ly"
      },
      "source": [
        "## Ad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uom11OKPP8sV"
      },
      "source": [
        "### Ad Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykpkKlkZogG3"
      },
      "source": [
        "def get_ad_title(soup):\n",
        "  titleBlock__title = soup.find('span', class_ = 'im-titleBlock__title')\n",
        "  return titleBlock__title.get_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKnLtSIsQA5Y"
      },
      "source": [
        "### Ad Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb-N84mK6Ipm"
      },
      "source": [
        "def get_ad_price(soup):\n",
        "  mainFeatures__price = soup.find_all('li', class_ = 'im-mainFeatures__price')\n",
        "  return mainFeatures__price[0].get_text().replace('\\n', '').strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQui5M3KQDZg"
      },
      "source": [
        "### Ad Main Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwAGku2_5V1"
      },
      "source": [
        "def get_ad_main_feature(soup):\n",
        "  main_features = {}\n",
        "  \n",
        "  mainFeatures = soup.find('div', class_ = 'im-mainFeatures')\n",
        "  \n",
        "  li_list = mainFeatures.find_all('li')\n",
        "  for li in li_list[1:]:\n",
        "    value = li.find('span', class_=\"im-mainFeatures__value\").get_text().replace('\\n', '').strip()\n",
        "    label = li.find('span', class_=\"im-mainFeatures__label\").get_text().replace('\\n', '').strip()\n",
        "    \n",
        "    if (label == 'bagno' or label == 'bagni'):\n",
        "      label = 'bagni'\n",
        "    \n",
        "    if (label == 'locale' or label == 'locali'):\n",
        "      label = 'locali'\n",
        "    \n",
        "    main_features[label] = value\n",
        "  \n",
        "  return main_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onVN270MQHLw"
      },
      "source": [
        "### Ad Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgHNdLhX23BI"
      },
      "source": [
        "def get_ad_description(soup):\n",
        "  description__text = soup.find('div', class_ = 'im-description__text')\n",
        "  return description__text.get_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA3RXVP-QKIb"
      },
      "source": [
        "### Ad Locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0-tj0Geel2"
      },
      "source": [
        "def get_ad_locations(soup):\n",
        "  location_list = []\n",
        "  \n",
        "  titleBlock__link = soup.find('a', class_ = 'im-titleBlock__link')\n",
        "  if titleBlock__link is None:\n",
        "    titleBlock__link = soup.find('h1', class_ = 'im-titleBlock__content')\n",
        "\n",
        "  location = titleBlock__link.find_all('span', class_ = 'im-location')\n",
        "  \n",
        "  try:\n",
        "    area = location[0].get_text().strip()\n",
        "  except IndexError:\n",
        "    area = ''\n",
        "  \n",
        "  try:\n",
        "    district = location[1].get_text().strip()\n",
        "  except IndexError:\n",
        "    district = ''\n",
        "\n",
        "  try:\n",
        "    address = location[2].get_text().strip()\n",
        "  except IndexError:\n",
        "    address = ''\n",
        "\n",
        "  return [area, district, address]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnDT1ZSOQNDd"
      },
      "source": [
        "### Ad Feature List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhuVyk5h_Kfb"
      },
      "source": [
        "def get_ad_feature_list(soup):\n",
        "  features = {}\n",
        "  \n",
        "  features__list = soup.find_all(\"dl\", class_ = \"im-features__list\")\n",
        "  \n",
        "  for feature_block in features__list:\n",
        "    feature__title_list = feature_block.find_all('dt', class_ = 'im-features__title')\n",
        "  \n",
        "    for feature__title in feature__title_list:\n",
        "      feature__value = feature__title.findNext('dd')\n",
        "  \n",
        "      if ('im-features__tagContainer' in feature__value.get('class')):\n",
        "        features__tag_array = []\n",
        "\n",
        "        features__tag_list = soup.find_all('span', class_ = 'im-features__tag')\n",
        "        for feature__tag in features__tag_list:\n",
        "          features__tag_array.append(feature__tag.get_text().strip())\n",
        "  \n",
        "        features__tag_list_string = ','.join(features__tag_array)\n",
        "        feature__value_2 = features__tag_list_string\n",
        "  \n",
        "      else:\n",
        "        feature__value_2 = feature__value.get_text().strip()\n",
        "  \n",
        "      feature__title_2 = feature__title.get_text().strip()\n",
        "      features['f_' + feature__title_2] = feature__value_2\n",
        "  \n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAw9UTlzQQkZ"
      },
      "source": [
        "### Ad Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLEg4LNxGf9L"
      },
      "source": [
        "def get_ad(url):\n",
        "  if 'p-' in url:\n",
        "    return get_ad_multi(url)\n",
        "  else:\n",
        "    return get_ad_single(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OWffZz4QWWw"
      },
      "source": [
        "### Ad Single"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILWk45lM2V27"
      },
      "source": [
        "def get_ad_single(url):\n",
        "  ads_list = []\n",
        "  ad_data = {}\n",
        "\n",
        "  ad_data['url'] = url\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    title = get_ad_title(soup);\n",
        "    ad_data['titolo'] = title\n",
        "\n",
        "    price = get_ad_price(soup);\n",
        "    ad_data['prezzo'] = price\n",
        "\n",
        "    main_features = get_ad_main_feature(soup)\n",
        "    if main_features:\n",
        "      ad_data.update(main_features)\n",
        "\n",
        "    description = get_ad_description(soup);\n",
        "    ad_data['descrizione'] = description\n",
        "\n",
        "    area, district, address = get_ad_locations(soup)\n",
        "    ad_data['area'] = area\n",
        "    ad_data['quartiere'] = district\n",
        "    ad_data['indirizzo'] = address\n",
        "\n",
        "    feature_list = get_ad_feature_list(soup)\n",
        "    if feature_list:\n",
        "      ad_data.update(feature_list)\n",
        "\n",
        "    ad_data['hashcode'] = hash(frozenset(ad_data.items()))\n",
        "\n",
        "    ads_list.append(ad_data)\n",
        "  \n",
        "  except Exception as e:\n",
        "    logging.exception(e)\n",
        "    print(url)\n",
        "    pass\n",
        "\n",
        "  return ads_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtrLpzqcQb5f"
      },
      "source": [
        "### Ad Multi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOCb5naQ2IML"
      },
      "source": [
        "def get_ad_multi(url):\n",
        "  ads_list = []\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    title = get_ad_title(soup);\n",
        "\n",
        "    area, district, address = get_ad_locations(soup)\n",
        "\n",
        "    main_features = get_ad_main_feature(soup)\n",
        "\n",
        "    description = get_ad_description(soup)\n",
        "\n",
        "    feature_list = get_ad_feature_list(soup)\n",
        "\n",
        "    properties__list = soup.find('ul', class_ = 'im-properties__list')\n",
        "    properties__item_list = properties__list.find_all('li', class_ = 'im-properties__item')\n",
        "    for properties__item in properties__item_list:\n",
        "      ad_data = {}\n",
        "\n",
        "      ad_data['url'] = url\n",
        "\n",
        "      ad_data['titolo'] = title\n",
        "\n",
        "      ad_data['area'] = area\n",
        "      ad_data['quartiere'] = district\n",
        "      ad_data['indirizzo'] = address\n",
        "      \n",
        "      price = get_ad_price(properties__item)\n",
        "      ad_data['prezzo'] = price\n",
        "\n",
        "      ad_data['descrizione'] = description\n",
        "\n",
        "      sub_features = get_ad_main_feature(properties__item)\n",
        "      if sub_features:\n",
        "        ad_data.update(sub_features)\n",
        "\n",
        "      title_2 = properties__item.find('p', class_ = 'nd-mediaObject__title').get_text().strip()\n",
        "      ad_data['titolo_2'] = title_2\n",
        "\n",
        "      description_2 = properties__item.find('div', class_ = 'im-properties__content').get_text()\n",
        "      ad_data['descrizione_2'] = description_2\n",
        "\n",
        "      if feature_list:\n",
        "        ad_data.update(feature_list)\n",
        "\n",
        "      ad_data['hashcode'] = hash(frozenset(ad_data.items()))\n",
        "\n",
        "      ads_list.append(ad_data)\n",
        "\n",
        "  except Exception as e:\n",
        "    logging.exception(e)\n",
        "    print(url)\n",
        "    pass\n",
        "  \n",
        "  return ads_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz7JD-opGhwY"
      },
      "source": [
        "### Read Links CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-evOLRfGpIJ"
      },
      "source": [
        "df_links = pd.read_csv('Links_1616797839_1_630.csv')\n",
        "ads_link_list = df_links['Links'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5smqhCWQfD2"
      },
      "source": [
        "### Ads Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DnnXijuFbWz"
      },
      "source": [
        "if PRODUCTION:\n",
        "  if GET_ADS_LIST:\n",
        "    df_ads = pd.DataFrame()\n",
        "\n",
        "    timestamp = str(int(time.time()))\n",
        "\n",
        "    first_ad = 5000\n",
        "    last_ad = 6000\n",
        "    #last_ad = len(ads_link_list)\n",
        "    \n",
        "    ads_csv = 'Ads_' + timestamp + '_' + str(first_ad) + '_' + str(last_ad - 1) + '.csv'\n",
        "\n",
        "    ads_list = []\n",
        "    for i in tqdm(range(first_ad, last_ad)):\n",
        "\n",
        "      try:\n",
        "        ad_data = get_ad(ads_link_list[i])\n",
        "        for ad in ad_data:\n",
        "          ads_list.append(ad)\n",
        "      except Exception as e:\n",
        "        logging.exception(e)\n",
        "        print(i)\n",
        "        pass\n",
        "      \n",
        "      sleep_default()\n",
        "    \n",
        "    df_ads = pd.DataFrame(ads_list)\n",
        "    df_ads.fillna('', inplace=True)\n",
        "    df_ads.to_csv(ads_csv, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj5iDlC3QpyI"
      },
      "source": [
        "### Display Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D11eWCH2Qe2w"
      },
      "source": [
        "  display(df_ads)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZbySh6ZJlOH"
      },
      "source": [
        "### Download Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d2rVUAiJqLs"
      },
      "source": [
        "files.download(ads_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozKoYBgmepLi"
      },
      "source": [
        "## Concat Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMfGVmeDevm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fca49937-f2f3-45a5-f2b9-8e0f1a895e0a"
      },
      "source": [
        "ads_folder = 'Ads'\n",
        "file_list = os.listdir(ads_folder)\n",
        "ads_files = [file for file in file_list if file.startswith('Ads')]\n",
        "ads_files.sort()\n",
        "\n",
        "df_files = [None] * len(ads_files)\n",
        "for idx, file in enumerate(ads_files):\n",
        "  df_files[idx] = pd.read_csv(os.path.join(ads_folder, file))\n",
        "\n",
        "df_final = pd.concat(df_files).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "ads_csv_final = 'Ads' + '_' + timestamp + '.csv'\n",
        "df_final.to_csv(ads_csv_final, index=False)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3984f8d3-ca20-4835-a1c8-f6b9b714a97f\", \"Ads_1616966209.csv\", 10786941)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn8r50QlGgaC"
      },
      "source": [
        "### Download Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a___P2QyGfBt"
      },
      "source": [
        "files.download(ads_csv_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL71vrUhJt3Q"
      },
      "source": [
        "# Clean Ads CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd5yxPYBInST"
      },
      "source": [
        "## Read Ads CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWtia4clIqkX"
      },
      "source": [
        "df_ads = pd.read_csv('Ads_1616966209.csv')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fei5KbG2R8J"
      },
      "source": [
        "## Remove multiple proprieties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyji7gaX2Vtm"
      },
      "source": [
        "df_ads_single = df_ads[~df_ads['url'].str.contains('p-')]\n",
        "#len(df_ads_single.index)\n",
        "# 5244 - 4873 = 371"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNDlVYfeKvak"
      },
      "source": [
        "## Print all DataFrame Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZH5B23qK1nN",
        "outputId": "25303681-c2d9-44c5-fec4-33c62f0ecc48"
      },
      "source": [
        "columns = list(df_ads_single.columns.values)\n",
        "for column in columns:\n",
        "  print(column)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "url\n",
            "titolo\n",
            "area\n",
            "quartiere\n",
            "indirizzo\n",
            "prezzo\n",
            "descrizione\n",
            "superficie\n",
            "bagni\n",
            "piano\n",
            "titolo_2\n",
            "descrizione_2\n",
            "f_immobile garantito\n",
            "f_riferimento e Data annuncio\n",
            "f_contratto\n",
            "f_unità\n",
            "f_Data di inizio lavori e di consegna prevista\n",
            "f_Tipo proprietà\n",
            "f_prezzo\n",
            "f_stato\n",
            "f_Indice prest. energetica rinnovabile\n",
            "f_Prestazione energetica del fabbricato\n",
            "f_Efficienza energetica\n",
            "hashcode\n",
            "locali\n",
            "f_tipologia\n",
            "f_superficie\n",
            "f_locali\n",
            "f_piano\n",
            "f_totale piani edificio\n",
            "f_Posti Auto\n",
            "f_disponibilità\n",
            "f_altre caratteristiche\n",
            "f_spese condominio\n",
            "f_anno di costruzione\n",
            "f_riscaldamento\n",
            "f_Climatizzazione\n",
            "f_certificazione energetica\n",
            "f_numero immobili\n",
            "f_aggiornato il\n",
            "data vendita\n",
            "f_Tipo vendita\n",
            "f_data vendita\n",
            "f_offerta minima\n",
            "f_rialzo minimo\n",
            "f_Spesa prenota debito\n",
            "f_Contributo non dovuto\n",
            "f_Tribunale\n",
            "f_termine presentazione\n",
            "f_lotto numero\n",
            "f_Deposito cauzionale\n",
            "f_luogo vendita\n",
            "f_Luogo presentazione\n",
            "f_categoria\n",
            "f_Procedura\n",
            "f_numero procedura\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amzuoBiRLIQM"
      },
      "source": [
        "## Remove useless Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ0i7e_nLK30"
      },
      "source": [
        "columns_useless = [\n",
        "  'area',\n",
        "  'titolo_2',\n",
        "  'descrizione_2',\n",
        "  'f_immobile garantito',\n",
        "  'f_contratto',\n",
        "  'f_unità',\n",
        "  'f_Data di inizio lavori e di consegna prevista',\n",
        "  'f_Indice prest. energetica rinnovabile',\n",
        "  'f_disponibilità',\n",
        "  'f_certificazione energetica',\n",
        "  'f_numero immobili',\n",
        "  'f_aggiornato il',\n",
        "  'data vendita',\n",
        "  'f_Tipo vendita',\n",
        "  'f_data vendita',\n",
        "  'f_offerta minima',\n",
        "  'f_rialzo minimo',\n",
        "  'f_Spesa prenota debito',\n",
        "  'f_Contributo non dovuto',\n",
        "  'f_Tribunale',\n",
        "  'f_termine presentazione',\n",
        "  'f_lotto numero',\n",
        "  'f_Deposito cauzionale',\n",
        "  'f_luogo vendita',\n",
        "  'f_Luogo presentazione',\n",
        "  'f_categoria',\n",
        "  'f_Procedura',\n",
        "  'f_numero procedura'\n",
        "]\n",
        "\n",
        "df_ads_single_columns = df_ads_single.drop(columns_useless, axis=1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myZX23MvQklC"
      },
      "source": [
        "## Print DataFrame Columns without useless Colums"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNW4nJuBQp7t",
        "outputId": "b742044c-a78f-4849-fa13-c553fdc83206"
      },
      "source": [
        "columns = list(df_ads_single_columns.columns.values)\n",
        "for column in columns:\n",
        "  print(column)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "url\n",
            "titolo\n",
            "quartiere\n",
            "indirizzo\n",
            "prezzo\n",
            "descrizione\n",
            "superficie\n",
            "bagni\n",
            "piano\n",
            "f_riferimento e Data annuncio\n",
            "f_Tipo proprietà\n",
            "f_prezzo\n",
            "f_stato\n",
            "f_Prestazione energetica del fabbricato\n",
            "f_Efficienza energetica\n",
            "hashcode\n",
            "locali\n",
            "f_tipologia\n",
            "f_superficie\n",
            "f_locali\n",
            "f_piano\n",
            "f_totale piani edificio\n",
            "f_Posti Auto\n",
            "f_altre caratteristiche\n",
            "f_spese condominio\n",
            "f_anno di costruzione\n",
            "f_riscaldamento\n",
            "f_Climatizzazione\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KEhAHktMpUb"
      },
      "source": [
        "## Check duplicates absence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xMb6xzpRIDa",
        "outputId": "d2f52e78-58fc-44e7-e98c-b680ef2a184d"
      },
      "source": [
        "print(df_ads_single_columns['url'].duplicated().any())\n",
        "print(df_ads_single_columns['hashcode'].duplicated().any())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-lQUI1xUKf9"
      },
      "source": [
        "## Get Geographic Coordinates from Ads Addresses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXoI2FrgWRut"
      },
      "source": [
        "### Install essentials packages for Geopandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzDWUhOBUSs2",
        "outputId": "8d0da723-ba9d-4f76-c638-6015208b5928"
      },
      "source": [
        "# Important library for many geopython libraries\n",
        "!apt install gdal-bin python-gdal python3-gdal \n",
        "\n",
        "# Install rtree - Geopandas requirment\n",
        "!apt install python3-rtree\n",
        "\n",
        "# Install Geopandas\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "\n",
        "# Install descartes - Geopandas requirment\n",
        "!pip install descartes\n",
        "\n",
        "# Install Folium for Geographic data visualization\n",
        "!pip install folium\n",
        "\n",
        "# Install plotlyExpress\n",
        "!pip install plotly_express"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "gdal-bin is already the newest version (2.2.3+dfsg-2).\n",
            "python-gdal is already the newest version (2.2.3+dfsg-2).\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-nose python3-numpy-dbg\n",
            "The following NEW packages will be installed:\n",
            "  python3-gdal python3-numpy\n",
            "0 upgraded, 2 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 2,288 kB of archives.\n",
            "After this operation, 13.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-numpy amd64 1:1.13.3-2ubuntu1 [1,943 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-gdal amd64 2.2.3+dfsg-2 [346 kB]\n",
            "Fetched 2,288 kB in 1s (2,005 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 160980 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.13.3-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-gdal.\n",
            "Preparing to unpack .../python3-gdal_2.2.3+dfsg-2_amd64.deb ...\n",
            "Unpacking python3-gdal (2.2.3+dfsg-2) ...\n",
            "Setting up python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Setting up python3-gdal (2.2.3+dfsg-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libspatialindex-c4v5 libspatialindex-dev libspatialindex4v5\n",
            "  python3-pkg-resources\n",
            "Suggested packages:\n",
            "  python3-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  libspatialindex-c4v5 libspatialindex-dev libspatialindex4v5\n",
            "  python3-pkg-resources python3-rtree\n",
            "0 upgraded, 5 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 671 kB of archives.\n",
            "After this operation, 3,948 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex4v5 amd64 1.8.5-5 [219 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-c4v5 amd64 1.8.5-5 [51.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-dev amd64 1.8.5-5 [285 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-rtree all 0.8.3+ds-1 [16.9 kB]\n",
            "Fetched 671 kB in 1s (752 kB/s)\n",
            "Selecting previously unselected package libspatialindex4v5:amd64.\n",
            "(Reading database ... 161390 files and directories currently installed.)\n",
            "Preparing to unpack .../libspatialindex4v5_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex4v5:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package libspatialindex-c4v5:amd64.\n",
            "Preparing to unpack .../libspatialindex-c4v5_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package libspatialindex-dev:amd64.\n",
            "Preparing to unpack .../libspatialindex-dev_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex-dev:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package python3-rtree.\n",
            "Preparing to unpack .../python3-rtree_0.8.3+ds-1_all.deb ...\n",
            "Unpacking python3-rtree (0.8.3+ds-1) ...\n",
            "Setting up libspatialindex4v5:amd64 (1.8.5-5) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
            "Setting up libspatialindex-dev:amd64 (1.8.5-5) ...\n",
            "Setting up python3-rtree (0.8.3+ds-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting git+git://github.com/geopandas/geopandas.git\n",
            "  Cloning git://github.com/geopandas/geopandas.git to /tmp/pip-req-build-8e1re4ps\n",
            "  Running command git clone -q git://github.com/geopandas/geopandas.git /tmp/pip-req-build-8e1re4ps\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas==0.9.0+7.gf5c54ed) (1.1.5)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas==0.9.0+7.gf5c54ed) (1.7.1)\n",
            "Collecting fiona>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/c2/67d1d0acbaaee3b03e5e22e3b96c33219cb5dd392531c9ff9cee7c2eb3e4/Fiona-1.8.18-cp37-cp37m-manylinux1_x86_64.whl (14.8MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 302kB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/72/d52e9ca81caef056062d71991b0e9b1d16af042245627c5d0e4916a36c4f/pyproj-3.0.1-cp37-cp37m-manylinux2010_x86_64.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas==0.9.0+7.gf5c54ed) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas==0.9.0+7.gf5c54ed) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas==0.9.0+7.gf5c54ed) (2.8.1)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas==0.9.0+7.gf5c54ed) (20.3.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas==0.9.0+7.gf5c54ed) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas==0.9.0+7.gf5c54ed) (1.15.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas==0.9.0+7.gf5c54ed) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: geopandas\n",
            "  Building wheel for geopandas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geopandas: filename=geopandas-0.9.0+7.gf5c54ed-py2.py3-none-any.whl size=995043 sha256=f50765c749880b1482a52b38bd473a1edbf351487545c6b9f1651970b0b454d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c12v2xmc/wheels/91/24/71/376c9c67192694168352afcccc2d264248f7e2cc6192997186\n",
            "Successfully built geopandas\n",
            "Installing collected packages: click-plugins, cligj, munch, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.18 geopandas-0.9.0+7.gf5c54ed munch-2.5.0 pyproj-3.0.1\n",
            "Requirement already satisfied: descartes in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from descartes) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->descartes) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->descartes) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->descartes) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->descartes) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->descartes) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->descartes) (1.15.0)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.7/dist-packages (0.8.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folium) (1.19.5)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from folium) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2020.12.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->folium) (1.1.1)\n",
            "Collecting plotly_express\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/d6/8a2906f51e073a4be80cab35cfa10e7a34853e60f3ed5304ac470852a08d/plotly_express-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from plotly_express) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from plotly_express) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from plotly_express) (1.1.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotly_express) (0.10.2)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from plotly_express) (4.4.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from plotly_express) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->plotly_express) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->plotly_express) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.1.0->plotly_express) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.1.0->plotly_express) (1.15.0)\n",
            "Installing collected packages: plotly-express\n",
            "Successfully installed plotly-express-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx5Kwz66UPrI"
      },
      "source": [
        "### Import Geopandas and Geopy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCEwRWqlT9F1"
      },
      "source": [
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from shapely.geometry import Point\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import folium\n",
        "import plotly_express as px\n",
        "import folium\n",
        "from folium.plugins import FastMarkerCluster"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uss1PKBJWksz",
        "outputId": "b93ab1aa-4ce8-4921-da82-631420e78698"
      },
      "source": [
        "locator = Nominatim(user_agent='myGeocoder')\n",
        "location = locator.geocode('Via Ferdinando Prampolini, 9, Ferrara')\n",
        "\n",
        "print(location.address)\n",
        "print(\"{}, {}\".format(location.latitude, location.longitude))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9, Via Ferdinando Prampolini, Giardino, Ferrara, Emilia-Romagna, 44122, Italia\n",
            "44.8302886, 11.6055812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ZlVubdvkpy"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    }
  ]
}